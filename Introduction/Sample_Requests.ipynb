{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run requests\n",
    "\n",
    "## ZOO-Project\n",
    "\n",
    "Here we will run CGI scripts from within Jupyter Notebok.\n",
    "\n",
    "### Root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "description": "Developement version of ZOO-Project OGC WPS. See http://www.zoo-project.org",
       "links": [
        {
         "href": "http://localhost/ogc-api/",
         "rel": "self",
         "title": "this document",
         "type": "application/json"
        },
        {
         "href": "http://localhost/ogc-api/index.html",
         "rel": "alternate",
         "title": "this document",
         "type": "text/html"
        },
        {
         "href": "http://localhost/ogc-api/api",
         "rel": "service-desc",
         "title": "the API definition",
         "type": "application/vnd.oai.openapi+json;version=3.0"
        },
        {
         "href": "http://localhost/ogc-api/api.html",
         "rel": "service-doc",
         "title": "the API definition",
         "type": "text/html"
        },
        {
         "href": "http://localhost/ogc-api/conformance",
         "rel": "http://www.opengis.net/def/rel/ogc/1.0/conformance",
         "title": "OGC API - Processes conformance classes implemented by this server",
         "type": "application/json"
        },
        {
         "href": "http://localhost/ogc-api/conformance.html",
         "rel": "alternate",
         "title": "OGC API - Processes conformance classes implemented by this server",
         "type": "text/html"
        },
        {
         "href": "http://localhost/ogc-api/processes",
         "rel": "http://www.opengis.net/def/rel/ogc/1.0/processes",
         "title": "The processes offered by this server",
         "type": "application/json"
        },
        {
         "href": "http://localhost/ogc-api/processes.html",
         "rel": "alternate",
         "title": "The processes offered by this server",
         "type": "text/html"
        },
        {
         "href": "http://localhost/ogc-api/jobs",
         "rel": "http://www.opengis.net/def/rel/ogc/1.0/job-list",
         "title": "Job Management",
         "type": "application/json"
        },
        {
         "href": "http://localhost/ogc-api/jobs.html",
         "rel": "alternate",
         "title": "Job Management",
         "type": "text/html"
        }
       ],
       "title": "The ZOO-Project OGC WPS Developement Server"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML, JSON\n",
    "import requests\n",
    "\n",
    "oapip_endpoint = 'http://localhost:8000/cgi-bin/zoo_loader.cgi?'\n",
    "\n",
    "headers= {\"accept\": \"application/json\"}\n",
    "\n",
    "query = '{}/'.format(oapip_endpoint)\n",
    "\n",
    "r = requests.get(query, headers=headers)\n",
    "\n",
    "JSON(r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "description": "This application chains together the 4 steps of the MeanShit framework, that is the MeanShiftSmoothing [1], the LSMSSegmentation [2], the LSMSSmallRegionsMerging [3] and the LSMSVectorization [4].This application can be a preliminary step for an object-based analysis.It generates a vector data file containing the regions extracted with the MeanShift algorithm. The spatial and range radius parameters allow adapting the sensitivity of the algorithm depending on the image dynamic and resolution. There is a step to remove small regions whose size (in pixels) is less than the given 'minsize' parameter. These regions are merged to a similar neighbor region. In the output vectors, there are additional fields to describe each region. In particular the mean and standard deviation (for each band) is computed for each region using the input image as support. If an optional 'imfield' image is given, it will be used as support image instead.",
       "id": "OTB.LargeScaleMeanShift",
       "inputs": {
        "cleanup": {
         "description": "If activated, the application will try to clean all temporary files it created",
         "schema": {
          "default": false,
          "type": "boolean"
         },
         "title": "If activated, the application will try to clean all temporary files it created"
        },
        "in": {
         "description": "The input image can be any single or multiband image. Beware of pontential imbalance between bands ranges as it may alter euclidean distance.",
         "extended-schema": {
          "oneOf": [
           {
            "allOf": [
             {
              "$ref": "http://zoo-project.org/dl/link.json"
             },
             {
              "properties": {
               "type": {
                "enum": [
                 "image/tiff",
                 "image/jpeg",
                 "image/png"
                ]
               }
              },
              "type": "object"
             }
            ]
           },
           {
            "properties": {
             "value": {
              "oneOf": [
               {
                "contentEncoding": "base64",
                "contentMediaType": "image/tiff",
                "type": "string"
               },
               {
                "contentEncoding": "base64",
                "contentMediaType": "image/jpeg",
                "type": "string"
               },
               {
                "contentEncoding": "base64",
                "contentMediaType": "image/png",
                "type": "string"
               }
              ]
             }
            },
            "required": [
             "value"
            ],
            "type": "object"
           }
          ]
         },
         "schema": {
          "oneOf": [
           {
            "contentEncoding": "base64",
            "contentMediaType": "image/tiff",
            "type": "string"
           },
           {
            "contentEncoding": "base64",
            "contentMediaType": "image/jpeg",
            "type": "string"
           },
           {
            "contentEncoding": "base64",
            "contentMediaType": "image/png",
            "type": "string"
           }
          ]
         },
         "title": "The input image can be any single or multiband image. Beware of pontential imbalance between bands ranges as it may alter euclidean distance."
        },
        "minsize": {
         "description": "Minimum Segment Size. If, after the segmentation, a segment is of size lower than this criterion, the segment is merged with the segment that has the closest sepctral signature.",
         "schema": {
          "default": 50,
          "nullable": true,
          "type": "integer"
         },
         "title": "Minimum Segment Size. If, after the segmentation, a segment is of size lower than this criterion, the segment is merged with the segment that has the closest sepctral signature."
        },
        "mode": {
         "description": "Type of segmented output",
         "schema": {
          "default": "vector",
          "enum": [
           "vector",
           "raster"
          ],
          "type": "string"
         },
         "title": "Type of segmented output"
        },
        "mode.raster.out": {
         "description": "It corresponds to the output of the small region merging step.",
         "schema": {
          "default": "uint8",
          "enum": [
           "uint8",
           "uint16",
           "int16",
           "int32",
           "int32",
           "float",
           "double"
          ],
          "type": "string"
         },
         "title": "It corresponds to the output of the small region merging step."
        },
        "mode.vector.imfield": {
         "description": "This is an optional support image that can be used to compute field values in each region. Otherwise, the input image is used as support.",
         "extended-schema": {
          "nullable": true,
          "oneOf": [
           {
            "allOf": [
             {
              "$ref": "http://zoo-project.org/dl/link.json"
             },
             {
              "properties": {
               "type": {
                "enum": [
                 "image/tiff",
                 "image/jpeg",
                 "image/png"
                ]
               }
              },
              "type": "object"
             }
            ]
           },
           {
            "properties": {
             "value": {
              "oneOf": [
               {
                "contentEncoding": "base64",
                "contentMediaType": "image/tiff",
                "type": "string"
               },
               {
                "contentEncoding": "base64",
                "contentMediaType": "image/jpeg",
                "type": "string"
               },
               {
                "contentEncoding": "base64",
                "contentMediaType": "image/png",
                "type": "string"
               }
              ]
             }
            },
            "required": [
             "value"
            ],
            "type": "object"
           }
          ]
         },
         "schema": {
          "oneOf": [
           {
            "contentEncoding": "base64",
            "contentMediaType": "image/tiff",
            "type": "string"
           },
           {
            "contentEncoding": "base64",
            "contentMediaType": "image/jpeg",
            "type": "string"
           },
           {
            "contentEncoding": "base64",
            "contentMediaType": "image/png",
            "type": "string"
           }
          ]
         },
         "title": "This is an optional support image that can be used to compute field values in each region. Otherwise, the input image is used as support."
        },
        "ram": {
         "description": "Available memory for processing (in MB)",
         "schema": {
          "default": 128,
          "nullable": true,
          "type": "integer"
         },
         "title": "Available memory for processing (in MB)"
        },
        "ranger": {
         "description": "Threshold on spectral signature euclidean distance (expressed in radiometry unit) to consider neighborhood pixel for averaging. Higher values will be less edge-preserving (more similar to simple average in neighborhood), whereas lower values will result in less noise smoothing. Note that this parameter has no effect on processing time.",
         "schema": {
          "default": 15,
          "format": "double",
          "nullable": true,
          "type": "number"
         },
         "title": "Threshold on spectral signature euclidean distance (expressed in radiometry unit) to consider neighborhood pixel for averaging. Higher values will be less edge-preserving (more similar to simple average in neighborhood), whereas lower values will result in less noise smoothing. Note that this parameter has no effect on processing time."
        },
        "spatialr": {
         "description": "Radius of the spatial neighborhood for averaging. Higher values will result in more smoothing and higher processing time.",
         "schema": {
          "default": 5,
          "nullable": true,
          "type": "integer"
         },
         "title": "Radius of the spatial neighborhood for averaging. Higher values will result in more smoothing and higher processing time."
        },
        "tilesizex": {
         "description": "Size of tiles along the X-axis for tile-wise processing.",
         "schema": {
          "default": 500,
          "type": "integer"
         },
         "title": "Size of tiles along the X-axis for tile-wise processing."
        },
        "tilesizey": {
         "description": "Size of tiles along the Y-axis for tile-wise processing.",
         "schema": {
          "default": 500,
          "type": "integer"
         },
         "title": "Size of tiles along the Y-axis for tile-wise processing."
        }
       },
       "jobControlOptions": [
        "sync-execute",
        "async-execute",
        "dismiss"
       ],
       "links": [
        {
         "href": "http://cs2022.geolabs.fr:8112/ogc-api/processes/OTB.LargeScaleMeanShift/execution",
         "rel": "http://www.opengis.net/def/rel/ogc/1.0/execute",
         "title": "Execute End Point",
         "type": "application/json"
        },
        {
         "href": "http://cs2022.geolabs.fr:8112/ogc-api/processes/OTB.LargeScaleMeanShift/execution.html",
         "rel": "alternate",
         "title": "Execute End Point",
         "type": "text/html"
        }
       ],
       "outputTransmission": [
        "value",
        "reference"
       ],
       "outputs": {
        "mode.raster.out": {
         "description": "It corresponds to the output of the small region merging step.",
         "extended-schema": {
          "oneOf": [
           {
            "allOf": [
             {
              "$ref": "http://zoo-project.org/dl/link.json"
             },
             {
              "properties": {
               "type": {
                "enum": [
                 "image/tiff",
                 "image/jpeg",
                 "image/png"
                ]
               }
              },
              "type": "object"
             }
            ]
           },
           {
            "properties": {
             "value": {
              "oneOf": [
               {
                "contentEncoding": "base64",
                "contentMediaType": "image/tiff",
                "type": "string"
               },
               {
                "contentEncoding": "base64",
                "contentMediaType": "image/jpeg",
                "type": "string"
               },
               {
                "contentEncoding": "base64",
                "contentMediaType": "image/png",
                "type": "string"
               }
              ]
             }
            },
            "required": [
             "value"
            ],
            "type": "object"
           }
          ]
         },
         "schema": {
          "oneOf": [
           {
            "contentEncoding": "base64",
            "contentMediaType": "image/tiff",
            "type": "string"
           },
           {
            "contentEncoding": "base64",
            "contentMediaType": "image/jpeg",
            "type": "string"
           },
           {
            "contentEncoding": "base64",
            "contentMediaType": "image/png",
            "type": "string"
           }
          ]
         },
         "title": "It corresponds to the output of the small region merging step."
        },
        "mode.vector.out": {
         "description": "The output GIS vector file, representing the vectorized version of the segmented image where the features of the polygons are the radiometric means and variances.",
         "extended-schema": {
          "oneOf": [
           {
            "allOf": [
             {
              "$ref": "http://zoo-project.org/dl/link.json"
             },
             {
              "properties": {
               "type": {
                "enum": [
                 "text/xml",
                 "application/vnd.google-earth.kml+xml",
                 "application/json",
                 "application/zip"
                ]
               }
              },
              "type": "object"
             }
            ]
           },
           {
            "properties": {
             "value": {
              "oneOf": [
               {
                "contentEncoding": "utf-8",
                "contentMediaType": "text/xml",
                "type": "string"
               },
               {
                "contentEncoding": "utf-8",
                "contentMediaType": "application/vnd.google-earth.kml+xml",
                "type": "string"
               },
               {
                "type": "object"
               },
               {
                "contentEncoding": "base64",
                "contentMediaType": "application/zip",
                "type": "string"
               }
              ]
             }
            },
            "required": [
             "value"
            ],
            "type": "object"
           }
          ]
         },
         "schema": {
          "oneOf": [
           {
            "contentEncoding": "utf-8",
            "contentMediaType": "text/xml",
            "type": "string"
           },
           {
            "contentEncoding": "utf-8",
            "contentMediaType": "application/vnd.google-earth.kml+xml",
            "type": "string"
           },
           {
            "type": "object"
           },
           {
            "contentEncoding": "base64",
            "contentMediaType": "application/zip",
            "type": "string"
           }
          ]
         },
         "title": "The output GIS vector file, representing the vectorized version of the segmented image where the features of the polygons are the radiometric means and variances."
        }
       },
       "title": "Large-scale segmentation using MeanShift",
       "version": "1.0.0"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML, JSON\n",
    "from IPython.display import IFrame\n",
    "from IPython.core.display import display\n",
    "\n",
    "import requests\n",
    "\n",
    "oapip_endpoint = 'http://cs2022.geolabs.fr:8112/cgi-bin/zoo_loader.cgi'\n",
    "\n",
    "headers= {\"accept\": \"application/json\"}\n",
    "\n",
    "query = '{}?/processes/OTB.LargeScaleMeanShift'.format(oapip_endpoint)\n",
    "\n",
    "r = requests.get(query, headers=headers)\n",
    "\n",
    "#dir(r)\n",
    "JSON(r.json())\n",
    "#display(IFrame('http://cs2022.geolabs.fr:8112/ogc-api/index.html', '100%', '600px'))\n",
    "\n",
    "#HTML(\"<iframe src='http://cs2022.geolabs.fr:8112/ogc-api/index.html' syle='width:100%; height:400px' ></iframe>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Processes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "links": [
        {
         "href": "http://localhost/ogc-api/processes",
         "rel": "self",
         "type": "application/json"
        },
        {
         "href": "http://localhost/ogc-api/processes.html",
         "rel": "alternate",
         "type": "text/html"
        }
       ],
       "numberTotal": 107,
       "processes": [
        {
         "description": "This application computes the modulus and the phase of a complex SAR image. The input should be a single band image with complex pixels.",
         "id": "OTB.ComputeModulusAndPhase",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.ComputeModulusAndPhase",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.ComputeModulusAndPhase.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "This application computes the modulus and the phase of a complex SAR image.",
         "version": "1.0.0"
        },
        {
         "description": "Estimate feature fuzzy model parameters using 2 vector data (ground truth samples and wrong samples).",
         "id": "OTB.DSFuzzyModelEstimation",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.DSFuzzyModelEstimation",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.DSFuzzyModelEstimation.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Estimate feature fuzzy model parameters using 2 vector data (ground truth samples and wrong samples).",
         "version": "1.0.0"
        },
        {
         "description": "This application performs a vector data classification based on a model file produced by the TrainVectorClassifier application.Features of the vector data output will contain the class labels decided by the classifier (maximal class label = 65535). There are two modes: 1) Update mode: add of the 'cfield' field containing the predicted class in the input file. 2) Write mode: copies the existing fields of the input file in the output file  and add the 'cfield' field containing the predicted class. If you have declared the output file, the write mode applies. Otherwise, the input file update mode will be applied.",
         "id": "OTB.VectorClassifier",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.VectorClassifier",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.VectorClassifier.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Performs a classification of the input vector data according to a model file.",
         "version": "1.0.0"
        },
        {
         "description": "Domain Transform application for wavelet and fourier",
         "id": "OTB.DomainTransform",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.DomainTransform",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.DomainTransform.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Domain Transform application for wavelet and fourier",
         "version": "1.0.0"
        },
        {
         "description": "This algorithm is based on the following publication:Martino Pesaresi and Jon Alti Benediktsson, Member, IEEE: A new approach for the morphological segmentation of high resolution satellite imagery.IEEE Transactions on geoscience and remote sensing, vol. 39, NO. 2, February 2001, p. 309-320.This application perform the following decision rule to classify a pixel between the three classes Convex, Concave and Flat. Let :math:`f` denote the input image and :math:`\\psi_",
         "id": "OTB.MorphologicalClassification",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.MorphologicalClassification",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.MorphologicalClassification.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Performs morphological convex, concave and flat classification on an input image channel",
         "version": "1.0.0"
        },
        {
         "description": "The application takes a sample data file as generated by the SampleExtraction application and generates synthetic samples to increase the number of available samples.",
         "id": "OTB.SampleAugmentation",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.SampleAugmentation",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.SampleAugmentation.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Generates synthetic samples from a sample data file.",
         "version": "1.0.0"
        },
        {
         "description": "SAR images are affected by speckle noise that inherently exists in and which degrades the image quality. It is caused by the coherent nature of back-scattered waves from multiple distributed targets. It is locally strong and it increases the mean Grey level of a local area. Reducing the speckle noise enhances radiometric resolution but tend to decrease the spatial resolution.Several different methods are used to eliminate speckle noise, based upon different mathematical models of the phenomenon. The application includes four methods: Lee [1], Frost [2], GammaMAP [3] and Kuan [4]. We sum up below the basic principle of this four methods:  * Lee : Estimate the signal by mean square error minimization (MMSE) on a sliding window.  * Frost : Also derived from the MMSE criteria with a weighted sum of the values within the window. The weighting factors decrease with distance from the pixel of interest.  * GammaMAP  : Derived under the assumption of the image follows a Gamma distribution.  * Kuan : Also derived from the MMSE criteria under the assumption of non stationary mean and variance. It is quite similar to Lee filter in form.",
         "id": "OTB.Despeckle",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.Despeckle",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.Despeckle.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Perform speckle noise reduction on SAR image.",
         "version": "1.0.0"
        },
        {
         "description": "This application performs a mathematical operation on several multi-band images and outputs the result into an image (multi- or mono-band, as opposed to the BandMath OTB-application). The mathematical formula is done by the muParserX libraries.The list of features and the syntax of muParserX is available at [1].As opposed to muParser (and thus the BandMath OTB-application [2]), muParserX supports vector expressions which allows outputting multi-band images.Hereafter is a brief reference of the muParserX syntaxFundamentals------------The formula can be written using:  * numerical values ( 2.3, -5, 3.1e4, ...)  * variables containing pixel values (please, note the indexing of inputs from 1 to N). Examples for the first input image:    * 'im1' a pixel from 1st input, made of n components (n bands)    * 'im1b2' the 2nd component of a pixel from 1st input (band index is 1-based)    * 'im1b2N3x4' a 3x4 pixels 'N'eighbourhood of a pixel the 2nd component of a pixel from the 1st input    * 'im1PhyX' horizontal (X-axis) spacing of the 1st input.    * 'im1PhyY' vertical spacing of the 1st input input.    * 'im1b2Mean' mean of the 2nd component of the 1st input (global statistics)    * 'im1b2Mini' minimum of the 2nd component of the 1st input (global statistics)    * 'im1b2Maxi' maximum of the 2nd component of the 1st input (global statistics)    * 'im1b2Sum' sum of the 2nd component of the 1st input (global statistics)    * 'im1b2Var' variance of the 2nd component of the 1st input (global statistics)    * 'idxX' and 'idxY' are the indices of the current pixel (generic variables)  * binary operators:    * '+' addition, '-' subtraction, '*' multiplication, '/' division    * '^' raise x to the power of y    * '",
         "id": "OTB.BandMathX",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.BandMathX",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.BandMathX.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "This application performs mathematical operations on several multiband images.",
         "version": "1.0.0"
        },
        {
         "description": "The application computes sampling rates for a set of input images. Before calling this application, each pair of image and training vectors has to be analysed with the application PolygonClassStatistics. The statistics file is then used to compute the sampling rates for each class in each image. Several types of sampling  are implemented. Each one is a combination of a mono-image strategy and a multi-image mode. The mono-image strategies are :  * smallest (default) : select the same number of sample in each class so that the smallest one is fully sampled.  * constant : select the same number of samples N in each class (with N below or equal to the size of the smallest class).  * byclass : set the required number for each class manually, with an input CSV file (first column is class name, second one is the required samples number).The multi-image modes (mim) are proportional, equal and custom. The custom mode lets the users choose the distribution of samples among the images. The different behaviours are described below. Ti(c) and Ni(c)  refers resp. to the total number and needed number of samples in image i for class c. Let's call L the total number of images.  * strategy = all    - Same behaviour for all modes : take all samples  * strategy = constant : let's call M the global number of samples required per class. For each image i and each class c:    - if mim = proportional, then Ni( c ) = M * Ti( c ) / sum_k( Tk(c) )    - if mim = equal       , then Ni( c ) = M / L    - if mim = custom      , then Ni( c ) = Mi where Mi is the custom requested number of samples for image i  * strategy = byClass : let's call M(c) the global number of samples for class c). For each image i and each class c:    - if mim = proportional, then Ni( c ) = M(c) * Ti( c ) / sum_k( Tk(c) )    - if mim = equal       , then Ni( c ) = M(c) / L    - if mim = custom      , then Ni( c ) = Mi(c) where Mi(c) is the custom requested number of samples for image i and class c  * strategy = percent : For each image i and each class c:    - if mim = proportional, then Ni( c ) = p * Ti( c ) where p is the global percentage of samples    - if mim = equal       , then Ni( c ) = p * sum_k(Tk(c)]/L where p is the global percentage of samples    - if mim = custom      , then Ni( c ) = p(i) * Ti(c) where p(i) is the percentage of samples for image i. c  * strategy = total : For each image i and each class c:    - if mim = proportional, then Ni( c ) = total * (sum_k(Ti(k))/sum_kl(Tl(k))) * (Ti(c)/sum_k(Ti(k))) where total is the total number of samples specified.    - if mim = equal       , then Ni( c ) = (total / L) * (Ti(c)/sum_k(Ti(k))) where total is the total number of samples specified.    - if mim = custom      , then Ni( c ) = total(i) * (Ti(c)/sum_k(Ti(k))) where total(i) is the total number of samples specified for image i.   * strategy = smallest class    - if mim = proportional, then the smallest class size (computed globally) is used for the strategy constant+proportional.    - if mim = equal       , then the smallest class size (computed globally) is used for the strategy constant+equal.    - if mim = custom      , then the smallest class is computed and used for each image separately.",
         "id": "OTB.MultiImageSamplingRate",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.MultiImageSamplingRate",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.MultiImageSamplingRate.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Compute sampling rate for an input set of images.",
         "version": "1.0.0"
        },
        {
         "description": "This application performs an image pixel type conversion (short, ushort, uchar, int, uint, float and double types are handled). The output image is written in the specified format (ie. that corresponds to the given extension). The conversion can include a rescale of the data range, by default it's set between the 2nd to the 98th percentile. The rescale can be linear or log2.  The choice of the output channels can be done with the extended filename, but less easy to handle. To do this, a 'channels' parameter allows you to select the desired bands at the output. There are 3 modes, the available choices are:  * grayscale :  to display mono image as standard color image  * rgb : select 3 bands in the input image (multi-bands)  * all : keep all bands.",
         "id": "OTB.DynamicConvert",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.DynamicConvert",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.DynamicConvert.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Change the pixel type and rescale the image's dynamic",
         "version": "1.0.0"
        },
        {
         "description": "This application computes MSE (Mean Squared Error), MAE (Mean Absolute Error) and PSNR (Peak Signal to Noise Ratio) between the channel of two images (reference and measurement). The user has to set the used channel and can specify a ROI.",
         "id": "OTB.CompareImages",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.CompareImages",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.CompareImages.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Estimator between 2 images.",
         "version": "1.0.0"
        },
        {
         "description": "The purpose of this application is to test parameters types.",
         "id": "OTB.TestApplication",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.TestApplication",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.TestApplication.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "This application helps developers to test parameters types",
         "version": "1.0.0"
        },
        {
         "description": "This application returns the UTM zone of an input geographic point.",
         "id": "OTB.ObtainUTMZoneFromGeoPoint",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.ObtainUTMZoneFromGeoPoint",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.ObtainUTMZoneFromGeoPoint.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "UTM zone determination from a geographic point.",
         "version": "1.0.0"
        },
        {
         "description": "This application trains a classifier from multiple input images or a csv file, in order to perform regression. Predictors are composed of pixel values in each band optionally centered and reduced using an XML statistics file produced by the ComputeImagesStatistics application. The output value for each predictor is assumed to be the last band (or the last column for CSV files). Training and validation predictor lists are built such that their size is inferior to maximum bounds given by the user, and the proportion corresponds to the balance parameter. Several classifier parameters can be set depending on the chosen classifier. In the validation process, the mean square error is computed between the ground truth and the estimated model. This application is based on LibSVM and on OpenCV Machine Learning classifiers, and is compatible with OpenCV 2.3.1 and later.",
         "id": "OTB.TrainRegression",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.TrainRegression",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.TrainRegression.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Train a classifier from multiple images to perform regression.",
         "version": "1.0.0"
        },
        {
         "description": "This application gives the value of a selected pixel. There are three ways to designate a pixel, with its index, its physical coordinate (in the physical space attached to the image), and with geographical coordinate system. Coordinates will be interpreted differently depending on which mode is chosen.",
         "id": "OTB.PixelValue",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.PixelValue",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.PixelValue.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Get the value of a pixel.",
         "version": "1.0.0"
        },
        {
         "description": "From one-band complex images (HH, HV, VH, VV), returns the selected decomposition. All the decompositions implemented are intended for the mono-static case (transmitter and receiver are co-located).There are two kinds of decomposition : coherent ones and incoherent ones.In the coherent case, only the Pauli decomposition is available.In the incoherent case, there the decompositions available : Huynen, Barnes, and H-alpha-A.User must provide three one-band complex images HH, HV or VH, and VV (mono-static case ",
         "id": "OTB.SARDecompositions",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.SARDecompositions",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.SARDecompositions.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "From one-band complex images (each one related to an element of the Sinclair matrix), returns the selected decomposition.",
         "version": "1.0.0"
        },
        {
         "description": "This application uses inverse sensor modelling combined with a choice of interpolation functions to resample a sensor geometry image into a ground geometry regular grid. The ground geometry regular grid is defined with respect to a map projection (see map parameter). The application offers several modes to estimate the output grid parameters (origin and ground sampling distance), including automatic estimation of image size, ground sampling distance, or both, from image metadata, user-defined ROI corners, or another ortho-image.A digital Elevation Model along with a geoid file can be specified to account for terrain deformations.In case of SPOT5 images, the sensor model can be approximated by an RPC model in order to speed-up computation.",
         "id": "OTB.OrthoRectification",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.OrthoRectification",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.OrthoRectification.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "This application allows ortho-rectifying optical and radar images from supported sensors.",
         "version": "1.0.0"
        },
        {
         "description": "Sentinel1 IW SLC products are composed of several burst overlapping in azimuth time for each subswath, separated by black lines [1]. The deburst operation consist in generating a continuous image in terms of azimuth time, by removing black separation lines as well as redundant lines between bursts.Note that the output sensor model is updated accordingly. This deburst operation is the perfect preprocessing step to orthorectify S1 IW SLC product with OTB [2] without suffering from artifacts caused by bursts separation.",
         "id": "OTB.SARDeburst",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.SARDeburst",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.SARDeburst.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "This application performs deburst of Sentinel1 IW SLC images by removing redundant lines.",
         "version": "1.0.0"
        },
        {
         "description": "Structural Feature Set [1] are based on the histograms of the pixels in multiple directions of the image. The SFSTextureExtraction application computes the  6 following features: SFS'Length, SFS'Width, SFS'PSI, SFS'W-Mean, SFS'Ratio and SFS'SD (Standard Deviation). The texture indices are computed from the neighborhood of each pixel. It is possible to change the length of the calculation line (spatial threshold), as well as the maximum difference between a pixel of the line and the pixel at the center of the neighborhood (spectral threshold) [2].",
         "id": "OTB.SFSTextureExtraction",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.SFSTextureExtraction",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.SFSTextureExtraction.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Computes Structural Feature Set textures on every pixel of the input image selected channel",
         "version": "1.0.0"
        },
        {
         "description": "This application validates or unvalidate the studied samples using the Dempster-Shafer theory.",
         "id": "OTB.VectorDataDSValidation",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.VectorDataDSValidation",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.VectorDataDSValidation.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Vector data validation based on the fusion of features using Dempster-Shafer evidence theory framework.",
         "version": "1.0.0"
        },
        {
         "description": "The application converts an image containing elevations into a PLY file, which is a file format to store 3D models. This format is adpated for visualization on software such as MeshLab [2] or CloudCompare [3]This application is part of the stereo reconstruction framework. The input data can be produced by the application DisparityMapToElevationMap.There are two types of supported input images:  * A DEM image, with a ground projection, containing elevation values. Each elevation value can be considered as a 3D point.  * A 3D grid image, containing 5 bands (the first 3 are the 3D coordinates of each point, the 5th is a validity mask where valid values are larger or equal to 1)The user shall also give a support image that contains color values for each 3D point. The color values will be embedded in the PLY file.",
         "id": "OTB.GeneratePlyFile",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.GeneratePlyFile",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.GeneratePlyFile.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Generate a 3D Ply file from a DEM and a color image.",
         "version": "1.0.0"
        },
        {
         "description": "This application allows performing image resampling from an input resampling grid.",
         "id": "OTB.GridBasedImageResampling",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.GridBasedImageResampling",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.GridBasedImageResampling.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Resamples an image according to a resampling grid",
         "version": "1.0.0"
        },
        {
         "description": "This application allows selecting the appropriate SRTM tiles that covers a list of images. It builds a list of the required tiles. Two modes are available: the first one download those tiles from the USGS SRTM3 website (http://dds.cr.usgs.gov/srtm/version2_1/SRTM3/), the second one list those tiles in a local directory. In both cases, you need to indicate the directory in which directory  tiles will be download or the location of local SRTM files.",
         "id": "OTB.DownloadSRTMTiles",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.DownloadSRTMTiles",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.DownloadSRTMTiles.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Download or list SRTM tiles",
         "version": "1.0.0"
        },
        {
         "description": "The application connects to Open Street Map server, downloads the data corresponding to the spatial extent of the support image, and filters the geometries based on OSM tags to produce a vector data file.This application can be used to download reference data to perform the training of a machine learning model (see for instance [1]).By default, the entire layer is downloaded. The application has a special mode to provide the list of available classes in the layers. The downloaded features are filtered by giving an OSM tag 'key'. In addition, the user can also choose what 'value' this key should have. More information about the OSM project at [2].",
         "id": "OTB.OSMDownloader",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.OSMDownloader",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.OSMDownloader.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Download vector data from OSM and store it to file",
         "version": "1.0.0"
        },
        {
         "description": "This application performs an image pixel type conversion (short, ushort, uchar, int, uint, float and double types are handled). The output image is written in the specified format (ie. that corresponds to the given extension). The conversion can include a rescale of the data range, by default it's set from 23777721343040160 9816014650020f the data values. The rescale can be linear or log2.  The choice of the output channels can be done with the extended filename, but less easy to handle. To do this, a 'channels' parameter allows you to select the desired bands at the output. There are 3 modes, the available choices are:  * grayscale :  to display mono image as standard color image  * rgb : select 3 bands in the input image (multi-bands)  * all : keep all bands.",
         "id": "OTB.Convert",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.Convert",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.Convert.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Convert an image to a different format, optionally rescaling the data and/or changing the pixel type.",
         "version": "1.0.0"
        },
        {
         "description": "This application generates a RPC sensor model from a list of Ground Control Points. At least 20 points are required for estimation without elevation support, and 40 points for estimation with elevation support. Elevation support will be automatically deactivated if an insufficient amount of points is provided. The application can optionally output a file containing accuracy statistics for each point, and a vector file containing segments representing points residues. The map projection parameter allows defining a map projection in which the accuracy is evaluated.",
         "id": "OTB.GenerateRPCSensorModel",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.GenerateRPCSensorModel",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.GenerateRPCSensorModel.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Generate a RPC sensor model from a list of Ground Control Points.",
         "version": "1.0.0"
        },
        {
         "description": "This application allows one to map a label image to a 8-bits RGB image (in both ways) using different methods. -The custom method allows one to use a custom look-up table. The look-up table is loaded from a text file where each line describes an entry. The typical use of this method is to colorise a classification map. -The continuous method allows mapping a range of values in a scalar input image to a colored image using continuous look-up table, in order to enhance image interpretation. Several look-up tables can been chosen with different color ranges.-The optimal method computes an optimal look-up table. When processing a segmentation label image (label to color), the color difference between adjacent segmented regions is maximized. When processing an unknown color image (color to label), all the present colors are mapped to a continuous label list. - The support image method uses a color support image to associate an average color to each region.",
         "id": "OTB.ColorMapping",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.ColorMapping",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.ColorMapping.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Maps an input label image to 8-bits RGB using look-up tables.",
         "version": "1.0.0"
        },
        {
         "description": "The application extracts samples values from animage using positions contained in a vector data file. ",
         "id": "OTB.SampleExtraction",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.SampleExtraction",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.SampleExtraction.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Extracts samples values from an image.",
         "version": "1.0.0"
        },
        {
         "description": "This application is the implementation of the histogram equalization algorithm. The idea of the algorithm is to use the whole available dynamic. In order to do so it computes a histogram over the image and then use the whole dynamic: meaning flattening the histogram. That gives us gain for each bin that transform the original histogram into the flat one. This gain is then apply on the original image.The application proposes several options to allow a finer result: - There is an option to limit contrast. We choose to limit the contrast by modifying the original histogram. To do so we clip the histogram at a given height and redistribute equally among the bins the clipped population. Then we add a local version of the algorithm. - It is possible to apply the algorithm on tiles of the image, instead of on the whole image. That gives us gain depending on the value of the pixel and its position in the image. In order to smoothen the result we interpolate the gain between tiles.",
         "id": "OTB.ContrastEnhancement",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.ContrastEnhancement",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.ContrastEnhancement.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "This application is the implementation of the histogram equalization algorithm. It can be used to enhance contrast in an image or to reduce the dynamic of the image without losing too much contrast. It offers several options as a no data value, a contrast limitation factor, a local version of the algorithm and also a mode to equalize the luminance of the image.",
         "version": "1.0.0"
        },
        {
         "description": "This application compares a machine segmentation (MS) with a partial ground truth segmentation (GT). The Hoover metrics are used to estimate scores for correct detection, over-segmentation, under-segmentation and missed detection. The application can output the overall Hoover scores along with coloredimages of the MS and GT segmentation showing the state of each region (correct detection, over-segmentation, under-segmentation, missed) The Hoover metrics are described in : Hoover et al., \"An experimental comparison of range image segmentation algorithms\", IEEE PAMI vol. 18, no. 7, July 1996.",
         "id": "OTB.HooverCompareSegmentation",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.HooverCompareSegmentation",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.HooverCompareSegmentation.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Compare two segmentations with Hoover metrics",
         "version": "1.0.0"
        },
        {
         "description": "Given a segmentation result (can be the out output parameter of the LSMSSegmentation application [2]) and the original image, it will merge segments whose size in pixels is lower than minsize parameter with the adjacent segments with the adjacent segment with closest radiometry and acceptable size.Small segments will be processed by increasing size: first all segments for which area is equal to 1 pixel will be merged with adjacent segments, then all segments of area equal to 2 pixels will be processed, until segments of area minsize. For large images one can use the tilesizex and tilesizey parameters for tile-wise processing, with the guarantees of identical results.The output of this application can be passed to the LSMSVectorization application [3] to complete the LSMS workflow.",
         "id": "OTB.LSMSSmallRegionsMerging",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.LSMSSmallRegionsMerging",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.LSMSSmallRegionsMerging.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "This application performs the third (optional) step of the exact Large-Scale Mean-Shift segmentation workflow [1].",
         "version": "1.0.0"
        },
        {
         "description": "This algorithm is derived from the following publication:Martino Pesaresi and Jon Alti Benediktsson, Member, IEEE: A new approachfor the morphological segmentation of high resolution satellite imagery.IEEE Transactions on geoscience and remote sensing, vol. 39, NO. 2,February 2001, p. 309-320.Depending of the profile selection, the application provides::- The multi scale geodesic morphological opening or closing profile of the input image.- The multi scale derivative of the opening or closing profile.- The parameter (called characteristic) of the maximum derivative value of the multi scale closing or opening profile for which this maxima occurs.- The labeled classification of the input image.The behavior of the classification is :Given :math:`x_1` and :math:`x_2` two membership values,:math:`L_1, L_2` two labels associated, and :math:`\\sigma` a tolerancevalue, the following decision rule is applied::math:`L = \\begin",
         "id": "OTB.MorphologicalProfilesAnalysis",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.MorphologicalProfilesAnalysis",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.MorphologicalProfilesAnalysis.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Performs morphological profiles analysis on an input image channel.",
         "version": "1.0.0"
        },
        {
         "description": "This application filters the input labeled image (with a maximal class label = 65535) using Majority Voting in a ball shaped neighbordhood. Majority Voting takes the more representative value of all the pixels identified by the ball shaped structuring element and then sets the center pixel to this majority label value.    -NoData is the label of the NOT classified pixels in the input image. These input pixels keep their NoData label in the output image.    -Pixels with more than 1 majority class are marked as Undecided if the parameter 'ip.suvbool == true', or keep their Original labels otherwise.",
         "id": "OTB.ClassificationMapRegularization",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.ClassificationMapRegularization",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.ClassificationMapRegularization.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Filters the input labeled image using Majority Voting in a ball shaped neighbordhood.",
         "version": "1.0.0"
        },
        {
         "description": "This application trains a classifier based on labeled geometries and a list of features to consider for classification.This application is based on LibSVM, OpenCV Machine Learning (2.3.1 and later), and Shark ML The output of this application is a text model file, whose format corresponds to the ML model type chosen. There is no image nor vector data output.",
         "id": "OTB.TrainVectorClassifier",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.TrainVectorClassifier",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.TrainVectorClassifier.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Train a classifier based on labeled geometries and a list of features to consider.",
         "version": "1.0.0"
        },
        {
         "description": "This application recursively apply geodesic decomposition. This algorithm is derived from the following publication:Martino Pesaresi and Jon Alti Benediktsson, Member, IEEE: A new approach for the morphological segmentation of high resolution satellite imagery.IEEE Transactions on geoscience and remote sensing, vol. 39, NO. 2, February 2001, p. 309-320.It provides a geodesic decomposition of the input image, with the following scheme. Let :math:`f_0` denote the input image, :math:`\\stackrel",
         "id": "OTB.MorphologicalMultiScaleDecomposition",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.MorphologicalMultiScaleDecomposition",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.MorphologicalMultiScaleDecomposition.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Perform a geodesic morphology based image analysis on an input image channel",
         "version": "1.0.0"
        },
        {
         "description": "This application gives, for each pixel, the power that would have been received by a SAR system with a basis different from the classical (H,V) one (polarimetric synthetis).The new basis A and B are indicated through two Jones vectors, defined by the user thanks to orientation (psi) and ellipticity (khi) parameters.These parameters are namely psii, khii, psir and khir. The suffixes (i) and (r) refer to the transmitting antenna and the receiving antenna respectively.Orientations and ellipticities are given in degrees, and are between -90/90 degrees and -45/45 degrees respectively. Four polarization architectures can be processed : 1. HH_HV_VH_VV : full polarization, general bistatic case.2. HH_HV_VV or HH_VH_VV : full polarization, monostatic case (transmitter and receiver are co-located).3. HH_HV : dual polarization.4. VH_VV : dual polarization.The application takes a complex vector image as input, where each band correspond to a particular emission/reception polarization scheme.User must comply with the band order given above, since the bands are used to build the Sinclair matrix.In order to determine the architecture, the application first relies on the number of bands of the input image.1. Architecture HH_HV_VH_VV is the only one with four bands, there is no possible confusion.2. Concerning HH_HV_VV and HH_VH_VV architectures, both correspond to a three channels image. But they are processed in the same way, as the Sinclair matrix is symmetric in the monostatic case.3. Finally, the two last architectures (dual polarizations), can't be distinguished only by the number of bands of the input image. User must then use the parameters emissionh and emissionv to indicate the architecture of the system : emissionh=1 and emissionv=0 --> HH_HV,  emissionh=0 and emissionv=1 --> VH_VV.Note : if the architecture is HH_HV, khii and psii are automatically both set to 0 degree; if the architecture is VH_VV, khii and psii are automatically set to 0 degree and 90 degrees respectively.It is also possible to force the calculation to co-polar or cross-polar modes.In the co-polar case, values for psir and khir will be ignored and forced to psii and khii; same as the cross-polar mode, where khir and psir will be forced to (psii + 90 degrees) and -khii.Finally, the result of the polarimetric synthetis is expressed in the power domain, through a one-band scalar image.Note: this application doesn't take into account the terms which do not depend on the polarization of the antennas. The parameter gain can be used for this purpose.More details can be found in the OTB CookBook (SAR processing chapter).",
         "id": "OTB.SARPolarSynth",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.SARPolarSynth",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.SARPolarSynth.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Gives, for each pixel, the power that would have been received by a SAR system with a basis different from the classical (H,V) one (polarimetric synthetis).",
         "version": "1.0.0"
        },
        {
         "description": "This application detects locally straight contours in a image. It is based on Burns, Hanson, and Riseman method and use an a contrario validation approach (Desolneux, Moisan, and Morel). The algorithm was published by Rafael Gromponevon Gioi, Jérémie Jakubowicz, Jean-Michel Morel and Gregory Randall. The given approach computes gradient and level lines of the image and detects aligned points in line support region. The application allows exporting the detected lines in a vector data.",
         "id": "OTB.LineSegmentDetection",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.LineSegmentDetection",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.LineSegmentDetection.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Detect line segments in raster",
         "version": "1.0.0"
        },
        {
         "description": "This Application converts a sensor point of an input image to a geographic point using the Forward Sensor Model of the input image.",
         "id": "OTB.ConvertSensorToGeoPoint",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.ConvertSensorToGeoPoint",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.ConvertSensorToGeoPoint.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Sensor to geographic coordinates conversion.",
         "version": "1.0.0"
        },
        {
         "description": "This application exports the input image in a kmz product that can be display in the Google Earth software. The user can set the size of the product size, a logo and a legend to the product. Furthemore, to obtain a product that fits the relief, a DEM can be used.",
         "id": "OTB.KmzExport",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.KmzExport",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.KmzExport.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Export the input image in a KMZ product.",
         "version": "1.0.0"
        },
        {
         "description": "This application generates a pair of deformation grid to stereo-rectify a pair of stereo images according to sensor modelling and a mean elevation hypothesis.This application is the first part of the stereo reconstruction framework. The output deformation grids can be passed to the GridBasedImageResampling application for actual resampling into epipolar geometry.There are several ways to set the elevation source:  * An arbitrary constant elevation  * A DEM directory  * Compute an average elevation from a DEMIf needed, the application can compute inverse resampling grids (from epipolar to original sensor geometry). Don't forget to check the other outputs from the application. For instance, the application gives the X and Y size of the rectified images, along with an estimated baseline ratio.",
         "id": "OTB.StereoRectificationGridGenerator",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.StereoRectificationGridGenerator",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.StereoRectificationGridGenerator.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Generates two deformation fields to resample in epipolar geometry, a pair of stereo images up to the sensor model precision",
         "version": "1.0.0"
        },
        {
         "description": "The first step in the classifier fusion based validation is to compute the chosen descriptors for each studied polyline. ",
         "id": "OTB.ComputePolylineFeatureFromImage",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.ComputePolylineFeatureFromImage",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.ComputePolylineFeatureFromImage.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "This application computes the chosen descriptors for each studied polyline contained in the input VectorData.",
         "version": "1.0.0"
        },
        {
         "description": "This application performs an image classification based on a model file produced by the TrainImagesClassifier application. Pixels of the output image will contain the class labels decided by the classifier (maximal class label = 65535). The input pixels can be optionally centered and reduced according to the statistics file produced by the ComputeImagesStatistics application. An optional input mask can be provided, in which case only input image pixels whose corresponding mask value is greater than 0 will be classified. By default, the remaining of pixels will be given the label 0 in the output image.",
         "id": "OTB.ImageClassifier",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.ImageClassifier",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.ImageClassifier.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Performs a classification of the input image according to a model file.",
         "version": "1.0.0"
        },
        {
         "description": "Set a specified field to a specified value on all features of a vector data.",
         "id": "OTB.VectorDataSetField",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.VectorDataSetField",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.VectorDataSetField.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Set a field in vector data.",
         "version": "1.0.0"
        },
        {
         "description": "This application builds a multi-resolution pyramid of the input image. User can specified the number of levels of the pyramid and the subsampling factor. To speed up the process, you can use the fast scheme option",
         "id": "OTB.MultiResolutionPyramid",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.MultiResolutionPyramid",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.MultiResolutionPyramid.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Build a multi-resolution pyramid of the image.",
         "version": "1.0.0"
        },
        {
         "description": "In order to be understood by the Orfeo ToolBox and the underlying OSSIM library, a geo-referenced Digital Elevation Model image can be converted into a general raster image, which consists in 3 files with the following extensions: .ras, .geom and .omd. Once converted, you have to place these files in a separate directory, and you can then use this directory to set the \"DEM Directory\" parameter of a DEM based OTB application or filter.",
         "id": "OTB.DEMConvert",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.DEMConvert",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.DEMConvert.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Converts a geo-referenced DEM image into a general raster file compatible with OTB DEM handling.",
         "version": "1.0.0"
        },
        {
         "description": "This application allows computing homologous points between images using keypoints.  SIFT or SURF keypoints can be used and the band on which keypoints are computed can be set independently for both images. The application offers two modes : the first is the full mode where keypoints are extracted from the full extent of both images (please note that in this mode large image file are not supported). The second mode, called geobins, allows one to set-up spatial binning to get fewer points spread across the entire image. In this mode, the corresponding spatial bin in the second image is estimated using geographical transform or sensor modelling, and is padded according to the user defined precision. Last, in both modes the application can filter matches whose colocalisation in first image exceed this precision. The elevation parameters are to deal more precisely with sensor modelling in case of sensor geometry data. The outvector option allows creating a vector file with segments corresponding to the localisation error between the matches. It can be useful to assess the precision of a registration for instance. The vector file is always reprojected to EPSG:4326 to allow display in a GIS. This is done via reprojection or by applying the image sensor models.",
         "id": "OTB.HomologousPointsExtraction",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.HomologousPointsExtraction",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.HomologousPointsExtraction.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Compute homologous points between images using keypoints",
         "version": "1.0.0"
        },
        {
         "description": "This application computes edge features on a selected channel of the input.It uses different filter such as gradient, Sobel and Touzi",
         "id": "OTB.EdgeExtraction",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.EdgeExtraction",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.EdgeExtraction.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "This application computes edge features on every pixel of the input image selected channel",
         "version": "1.0.0"
        },
        {
         "description": "Apply the Vertex Component Analysis [1] toan hyperspectral image to extract endmembers. Given a set of mixedspectral vectors (multispectral or hyperspectral), the applicationestimates the spectral signature of reference substances also knownas endmembers.",
         "id": "OTB.VertexComponentAnalysis",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.VertexComponentAnalysis",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.VertexComponentAnalysis.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Given a set of mixed spectral vectors, estimatereference substances also known as endmembers using the VertexComponent Analysis algorithm.",
         "version": "1.0.0"
        },
        {
         "description": "This application allows one to performs block-matching to estimate pixel-wise disparities for a pair of images in epipolar geometry.This application is part of the stereovision pipeline. It can be used after having computed epipolar grids (with StereoRectificationGridGenerator) and resampled each input image into epipolar geometry (with GridBasedImageResampling).The application searches locally for the displacement between a reference image and a secondary image. The correspondence is evaluated for each pixel, based on a pair of local neighborhood windows. The displacement evaluated can be 1D (along lines) or 2D. Parameters allow setting the minimum and maximum disparities to search (both for horizontal and vertical directions). A winner-take-all approach is used to select the best match. There are different metrics implemented to evaluate the match between two local windows:  * SSD : Sum of Squared Distances  * NCC : Normalized Cross-Correlation  * Lp  : Lp pseudo normOnce the best integer disparity is found, an optional step of sub-pixel disparity estimation can be performed, with various algorithms (triangular interpolation, parabollic interpolation, dichotimic search). As post-processing, there is an optional step of median filtering on the disparities. One can chose input masks (related to the left and right input image) of pixels for which the disparity should be investigated. Additionally, two criteria can be optionally used to disable disparity investigation for some pixel: a no-data value, and a threshold on the local variance. This allows one to speed-up computation by avoiding to investigate disparities that will not be reliable anyway. For efficiency reasons, if the image of optimal metric values is desired, it will be concatenated to the output image (which will then have three bands : horizontal disparity, vertical disparity and metric value). One can split these images afterward.",
         "id": "OTB.BlockMatching",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.BlockMatching",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.BlockMatching.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Performs block-matching to estimate pixel-wise disparities between two images.",
         "version": "1.0.0"
        },
        {
         "description": "The application selects a set of samples from geometries intended for training (they should have a field giving the associated class). First of all, the geometries must be analyzed by the PolygonClassStatistics application to compute statistics about the geometries, which are summarized in an xml file. Then, this xml file must be given as input to this application (parameter instats).The input support image and the input training vectors shall be given in parameters 'in' and 'vec' respectively. Only the sampling grid (origin, size, spacing)will be read in the input image.There are several strategies to select samples (parameter strategy) :   - smallest (default) : select the same number of sample in each class so that the smallest one is fully sampled.  - constant : select the same number of samples N in each class (with N below or equal to the size of the smallest class).  - byclass : set the required number for each class manually, with an input CSV file (first column is class name, second one is the required samples number).  - percent: set a target global percentage of samples to use. Class proportions will be respected.   - total: set a target total number of samples to use. Class proportions will be respected. There is also a choice on the sampling type to performs :   - periodic : select samples uniformly distributed  - random : select samples randomly distributedOnce the strategy and type are selected, the application outputs samples positions(parameter out).The other parameters to look at are :   - layer : index specifying from which layer to pick geometries.  - field : set the field name containing the class.  - mask : an optional raster mask can be used to discard samples.  - outrates : allows outputting a CSV file that summarizes the sampling rates for each class.As with the PolygonClassStatistics application, different types  of geometry are supported : polygons, lines, points. The behavior of this application is different for each type of geometry :   - polygon: select points whose center is inside the polygon  - lines  : select points intersecting the line  - points : select closest point to the provided point",
         "id": "OTB.SampleSelection",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.SampleSelection",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.SampleSelection.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Selects samples from a training vector data set.",
         "version": "1.0.0"
        },
        {
         "description": "This application computes radiometric indices using the relevant channels of the input image. The output is a multi band image into which each channel is one of the selected indices.",
         "id": "OTB.RadiometricIndices",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.RadiometricIndices",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.RadiometricIndices.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Compute radiometric indices.",
         "version": "1.0.0"
        },
        {
         "description": "This application allows converting classical polarimetric matrices to each other.For instance, it is possible to get the coherency matrix from the Sinclar one, or the Mueller matrix from the coherency one.The filters used in this application never handle matrices, but images where each band is related to their elements.As most of the time SAR polarimetry handles symmetric/hermitian matrices, only the relevant elements are stored, so that the images representing them have a minimal number of bands.For instance, the coherency matrix size is 3x3 in the monostatic case, and 4x4 in the bistatic case : it will thus be stored in a 6-band or a 10-band complex image (the diagonal and the upper elements of the matrix).The Sinclair matrix is a special case : it is always represented as 3 or 4 one-band complex images (for mono- or bistatic case).The available conversions are listed below:--- Monostatic case ---1 msinclairtocoherency --> Sinclair matrix to coherency matrix (input : 3 x 1 complex channel (HH, HV or VH, VV) | output :  6 complex channels)2 msinclairtocovariance --> Sinclair matrix to covariance matrix (input : 3 x 1 complex channel (HH, HV or VH, VV) | output :  6 complex channels)3 msinclairtocircovariance --> Sinclair matrix to circular covariance matrix (input : 3 x 1 complex channel (HH, HV or VH, VV) | output :  6 complex channels)4 mcoherencytomueller --> Coherency matrix to Mueller matrix (input : 6 complex channels | 16 real channels)5 mcovariancetocoherencydegree --> Covariance matrix to coherency degree (input : 6 complex channels | 3 complex channels)6 mcovariancetocoherency --> Covariance matrix to coherency matrix (input : 6 complex channels | 6 complex channels)7 mlinearcovariancetocircularcovariance --> Covariance matrix to circular covariance matrix (input : 6 complex channels | output : 6 complex channels)--- Bistatic case ---8 bsinclairtocoherency --> Sinclair matrix to coherency matrix (input : 4 x 1 complex channel (HH, HV, VH, VV) | 10 complex channels)9 bsinclairtocovariance --> Sinclair matrix to covariance matrix (input : 4 x 1 complex channel (HH, HV, VH, VV) | output : 10 complex channels)10 bsinclairtocircovariance --> Sinclair matrix to circular covariance matrix (input : 4 x 1 complex channel (HH, HV, VH, VV) | output : 10 complex channels)--- Both cases ---11 sinclairtomueller --> Sinclair matrix to Mueller matrix (input : 4 x 1 complex channel (HH, HV, VH, VV) | output : 16 real channels)12 muellertomcovariance --> Mueller matrix to covariance matrix (input : 16 real channels | output : 6 complex channels)13 muellertopoldegandpower --> Mueller matrix to polarization degree and power (input : 16 real channels | output : 4 real channels)",
         "id": "OTB.SARPolarMatrixConvert",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.SARPolarMatrixConvert",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.SARPolarMatrixConvert.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "This applications allows converting classical polarimetric matrices to each other.",
         "version": "1.0.0"
        },
        {
         "description": "This application will apply a trained machine learning model on the selected feature to get a classification of each geometry contained in an OGR layer. The list of feature must match the list used for training. The predicted label is written in the user defined field for each geometry.",
         "id": "OTB.OGRLayerClassifier",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.OGRLayerClassifier",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.OGRLayerClassifier.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Classify an OGR layer based on a machine learning model and a list of features to consider.",
         "version": "1.0.0"
        },
        {
         "description": "The application allows converting pixel values from DN (for Digital Numbers) to reflectance. Calibrated values are called surface reflectivity and its values lie in the range [0, 1].The first level is called Top Of Atmosphere (TOA) reflectivity. It takes into account the sensor gain, sensor spectral response and the solar illuminations.The second level is called Top Of Canopy (TOC) reflectivity. In addition to sensor gain and solar illuminations, it takes into account the optical thickness of the atmosphere, the atmospheric pressure, the water vapor amount, the ozone amount, as well as the composition and amount of aerosol gasses.It is also possible to indicate an AERONET file which contains atmospheric parameters (version 1 and version 2 of Aeronet file are supported. Note that computing TOC reflectivity will internally compute first TOA and then TOC reflectance. --------------------------If the sensor is not supported by the metadata interface factory of OTB, users still have the possibility to give the needed parameters to the application.For TOA conversion, these parameters are : - day and month of acquisition, or flux normalization coefficient;- sun elevation angle;- gains and biases, one pair of values for each band (passed by a file);- solar illuminations, one value for each band (passed by a file).For the conversion from DN (for Digital Numbers) to spectral radiance (or 'TOA radiance') L, the following formula is used :(1)L(b) = DN(b)/gain(b)+bias(b)(in W/m2/steradians/micrometers)with b being a band ID.These values are provided by the user thanks to a simple txt file with two lines, one for the gains and one for the biases.Each value must be separated with colons (:), with eventual spaces. Blank lines are not allowed. If a line begins with the '#' symbol, then it is considered as comments.Note that sometimes, the values provided by certain metadata files assume the formula L(b) = gain(b)*DC(b)+bias(b).In this case, be sure to provide the inverse gain values so that the application can correctly interpret them.In order to convert TOA radiance to TOA reflectance, the following formula is used :(2)R(b) = (pi*L(b)*d*d) / (ESUN(b)*cos(θ))(no dimension)where : - L(b) is the spectral radiance for band b - pi is the famous mathematical constant (3.14159...) - d is the earth-sun distance (in astronomical units) and depends on the acquisition's day and month - ESUN(b) is the mean TOA solar irradiance (or solar illumination) in W/m2/micrometers- θ is the solar zenith angle in degrees.Note that the application asks for the solar elevation angle, and will perform the conversion to the zenith angle itself (zenith_angle = 90 - elevation_angle , units : degrees).Note also that ESUN(b) not only depends on the band b, but also on the spectral sensitivity of the sensor in this particular band. In other words, the influence of spectral sensitivities is included within the ESUN different values.These values are provided by the user thanks to a txt file following the same convention as before.Instead of providing the date of acquisition, the user can also provide a flux normalization coefficient 'fn'. The formula used instead will be the following : (3) R(b) = (pi*L(b)) / (ESUN(b)*fn*fn*cos(θ)) Whatever the formula used (2 or 3), the user should pay attention to the interpretation of the parameters he will provide to the application, by taking into account the original formula that the metadata files assumes.Below, we give two examples of txt files containing information about gains/biases and solar illuminations :- gainbias.txt :# Gain values for each band. Each value must be separated with colons (:), with eventual spaces. Blank lines not allowed.10.4416 : 9.529 : 8.5175 : 14.0063# Bias values for each band.0.0 : 0.0 : 0.0 : 0.0- solarillumination.txt : # Solar illumination values in watt/m2/micron ('micron' means actually 'for each band').# Each value must be separated with colons (:), with eventual spaces. Blank lines not allowed.1540.494123 : 1826.087443 : 1982.671954 : 1094.747446Finally, the 'Logs' tab provides useful messages that can help the user in knowing the process different status.",
         "id": "OTB.OpticalCalibration",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.OpticalCalibration",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.OpticalCalibration.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Perform optical calibration TOA/TOC (Top Of Atmosphere/Top Of Canopy). Supported sensors: QuickBird, Ikonos, WorldView2, Formosat, Spot5, Pleiades, Spot6, Spot7. For other sensors the application also allows providing calibration parameters manually.",
         "version": "1.0.0"
        },
        {
         "description": "This application splits a N-bands image into N mono-band images. The output images filename will be generated from the output parameter. Thus, if the input image has 2 channels, and the user has set as output parameter, outimage.tif, the generated images will be outimage_0.tif and outimage_1.tif.",
         "id": "OTB.SplitImage",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.SplitImage",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.SplitImage.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Split a N multiband image into N images.",
         "version": "1.0.0"
        },
        {
         "description": "This application allows you to fuse several classification maps and produces a single more robust classification map. Fusion is done either by mean of Majority Voting, or with the Dempster Shafer combination method on class labels.  - MAJORITY VOTING: for each pixel, the class with the highest number of votes is selected.  - DEMPSTER SHAFER: for each pixel, the class label for which the Belief Function is maximal is selected. This Belief Function is calculated by mean of the Dempster Shafer combination of Masses of Belief, and indicates the belief that each input classification map presents for each label value. Moreover, the Masses of Belief are based on the input confusion matrices of each classification map, either by using the PRECISION or RECALL rates, or the OVERALL ACCURACY, or the KAPPA coefficient. Thus, each input classification map needs to be associated with its corresponding input confusion matrix file for the Dempster Shafer fusion.  - Input pixels with the NODATA label are not handled in the fusion of classification maps. Moreover, pixels for which all the input classifiers are set to NODATA keep this value in the output fused image.  - In case of number of votes equality, the UNDECIDED label is attributed to the pixel.",
         "id": "OTB.FusionOfClassifications",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.FusionOfClassifications",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.FusionOfClassifications.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Fuses several classifications maps of the same image on the basis of class labels.",
         "version": "1.0.0"
        },
        {
         "description": "This application reads a geom file containing a sensor model and a text file containing a list of ground control point, and performs a least-square fit of the sensor model adjustable parameters to these tie points. It produces an updated geom file as output, as well as an optional ground control points based statistics file and a vector file containing residues. The output geom file can then be used to ortho-rectify the data more accurately. Plaease note that for a proper use of the application, elevation must be correctly set (including DEM and geoid file). The map parameters allows one to choose a map projection in which the accuracy will be estimated in meters.",
         "id": "OTB.RefineSensorModel",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.RefineSensorModel",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.RefineSensorModel.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Perform least-square fit of a sensor model to a set of tie points",
         "version": "1.0.0"
        },
        {
         "description": "This application will produce a labeled image where neighbor pixels whose range distance is below range radius (and optionally spatial distance below spatial radius) will be grouped together into the same cluster. For large images one can use the tilesizex and tilesizey parameters for tile-wise processing, with the guarantees of identical results.Filtered range image and spatial image should be created with the MeanShiftSmoothing application outputs (fout and foutpos) [2], with modesearch parameter disabled. If spatial image is not set, the application will only process the range image and spatial radius parameter will not be taken into account.Please note that this application will generate a lot of temporary files (as many as the number of tiles), and will therefore require twice the size of the final result in term of disk space. The cleanup option (activated by default) allows removing all temporary file as soon as they are not needed anymore (if cleanup is activated, tmpdir set and tmpdir does not exists before running the application, it will be removed as well during cleanup). The tmpdir option allows defining a directory where to write the temporary files.Please also note that the output image type should be set to uint32 to ensure that there are enough labels available.The output of this application can be passed to the LSMSSmallRegionMerging [3] or LSMSVectorization [4] applications to complete the LSMS workflow.",
         "id": "OTB.LSMSSegmentation",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.LSMSSegmentation",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.LSMSSegmentation.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "This application performs the second step of the exact Large-Scale Mean-Shift segmentation workflow (LSMS) [1].",
         "version": "1.0.0"
        },
        {
         "description": "This application performs P+XS pansharpening. Pansharpening is a process of merging high-resolution panchromatic and lower resolution multispectral imagery to create a single high-resolution color image. Algorithms available in the applications are: RCS, bayesian fusion and Local Mean and Variance Matching(LMVM).",
         "id": "OTB.Pansharpening",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.Pansharpening",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.Pansharpening.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Perform P+XS pansharpening",
         "version": "1.0.0"
        },
        {
         "description": "This application scales the given image pixel intensity between two given values.By default min (resp. max) value is set to 0 (resp. 255).Input minimum and maximum values is automatically computed for all image bands.",
         "id": "OTB.Rescale",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.Rescale",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.Rescale.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Rescale the image between two given values.",
         "version": "1.0.0"
        },
        {
         "description": "This application performs binary morphological operations on a mono band image or a channel of the input.",
         "id": "OTB.BinaryMorphologicalOperation",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.BinaryMorphologicalOperation",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.BinaryMorphologicalOperation.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Performs morphological operations on an input image channel",
         "version": "1.0.0"
        },
        {
         "description": "This application allows one to perform a masking, connected components segmentation and object based image filtering. First and optionally, a mask can be built based on user-defined criterions to select pixels of the image which will be segmented. Then a connected component segmentation is performed with a user defined criterion to decide whether two neighbouring pixels belong to the same segment or not. After this segmentation step, an object based image filtering is applied using another user-defined criterion reasoning on segment properties, like shape or radiometric attributes. Criterions are mathematical expressions analysed by the MuParser library (http://muparser.sourceforge.net/). For instance, expression \"((b1>80) and intensity>95)\" will merge two neighbouring pixel in a single segment if their intensity is more than 95 and their value in the first image band is more than 80. See parameters documentation for a list of available attributes. The output of the object based image filtering is vectorized and can be written in shapefile or KML format. If the input image is in raw geometry, resulting polygons will be transformed to WGS84 using sensor modelling before writing, to ensure consistency with GIS software. For this purpose, a Digital Elevation Model can be provided to the application. The whole processing is done on a per-tile basis for large images, so this application can handle images of arbitrary size.",
         "id": "OTB.ConnectedComponentSegmentation",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.ConnectedComponentSegmentation",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.ConnectedComponentSegmentation.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Connected component segmentation and object based image filtering of the input image according to user-defined criterions.",
         "version": "1.0.0"
        },
        {
         "description": "This application extracts a Region Of Interest with user parameters. There are four mode of extraction. The standard mode allows the user to enter one point (upper left corner of the region to extract) and a size. The extent mode needs two points (upper left corner and lower right) and the radius mode need the center of the region and the radius : it will extract the rectangle containing the circle defined and limited by the image dimension. The fit mode needs a reference image or vector and the dimension of the extracted region will be the same as the extent of the reference. Different units are available such as pixel, image physical space or longitude and latitude.",
         "id": "OTB.ExtractROI",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.ExtractROI",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.ExtractROI.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Extract a ROI defined by the user.",
         "version": "1.0.0"
        },
        {
         "description": "This application predict output values from an input image, based on a regression model file produced by the TrainRegression application. Pixels of the output image will contain the predicted values fromthe regression model (single band). The input pixels can be optionally centered and reduced according to the statistics file produced by the ComputeImagesStatistics application. An optional input mask can be provided, in which case only input image pixels whose corresponding mask value is greater than 0 will be processed. The remaining of pixels will be given the value 0 in the output image.",
         "id": "OTB.PredictRegression",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.PredictRegression",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.PredictRegression.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Performs a prediction of the input image according to a regression model file.",
         "version": "1.0.0"
        },
        {
         "description": "This application iterates over each vertex in the input vector data file and performs a transformation on this vertex.It is the equivalent of [1] that transforms images. For instance, if you extract the envelope of an image with [2], and you transform this image with [1], you may want to use this application to operate the same transform on the envelope.The applied transformation is a 2D similarity. It manages translation, rotation, scaling, and can be centered or not. Note that the support image is used to define the reference coordinate system in which the transform is applied. For instance the input vector data can have WGS84 coordinates, the support image is in UTM, so a translation of 1 pixel along X corresponds to the X pixel size of the input image along the X axis of the UTM coordinates frame. This image can also be in sensor geometry.",
         "id": "OTB.VectorDataTransform",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.VectorDataTransform",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.VectorDataTransform.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Apply a transform to each vertex of the input VectorData",
         "version": "1.0.0"
        },
        {
         "description": "This application allows one to perform various segmentation algorithms on a multispectral image.Available segmentation algorithms are two different versions of Mean-Shift segmentation algorithm (one being multi-threaded), simple pixel based connected components according to a user-defined criterion, and watershed from the gradient of the intensity (norm of spectral bands vector). The application has two different modes that affects the nature of its output.In raster mode, the output of the application is a classical image of unique labels identifying the segmented regions. The labeled output can be passed to the ColorMapping application to render regions with contrasted colours. Please note that this mode loads the whole input image into memory, and as such can not handle large images.  To segment large data, one can use the vector mode. In this case, the output of the application is a vector file or database. The input image is split into tiles (whose size can be set using the tilesize parameter), and each tile is loaded, segmented with the chosen algorithm, vectorized, and written into the output file or database. This piece-wise behavior ensure that memory will never get overloaded, and that images of any size can be processed. There are few more options in the vector mode. The simplify option allows simplifying the geometry (i.e. remove nodes in polygons) according to a user-defined tolerance. The stitch option tries to stitch together the polygons corresponding to segmented region that may have been split by the tiling scheme. ",
         "id": "OTB.Segmentation",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.Segmentation",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.Segmentation.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Performs segmentation of an image, and output either a raster or a vector file. In vector mode, large input datasets are supported.",
         "version": "1.0.0"
        },
        {
         "description": "This application performs images channels concatenation. It reads the input image list (single or multi-channel) and generates a single multi-channel image. The channel order is the same as the list.",
         "id": "OTB.ConcatenateImages",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.ConcatenateImages",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.ConcatenateImages.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Concatenate a list of images of the same size into a single multi-channel one.",
         "version": "1.0.0"
        },
        {
         "description": "Given a segmentation result (label image), that may come from the LSMSSegmentation [2] application (out parameter) or have been processed for small regions merging [3] (out parameter), it will convert it to a GIS vector file containing one polygon per segment. Each polygon contains additional fields: mean and variance of each channels from input image (in parameter), segmentation image label, number of pixels in the polygon. For large images one can use the tilesizex and tilesizey parameters for tile-wise processing, with the guarantees of identical results.",
         "id": "OTB.LSMSVectorization",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.LSMSVectorization",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.LSMSVectorization.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "This application performs the fourth step of the exact Large-Scale Mean-Shift segmentation workflow [1].",
         "version": "1.0.0"
        },
        {
         "description": "Automatically mosaic a set of non overlapping tile files into a single image. Images must have a matching number of bands and they must be listed in lexicographic order.",
         "id": "OTB.TileFusion",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.TileFusion",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.TileFusion.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Fusion of an image made of several tile files.",
         "version": "1.0.0"
        },
        {
         "description": "This application uses a disparity map computed from a stereo image pair to produce an elevation map on the ground area covered by the stereo pair.This application is part of the stereo reconstruction pipeline. It can be used after having computed the disparity map with BlockMatching.The needed inputs are : the disparity map, the stereo pair (in original geometry) and the epipolar deformation grids. These grids (computed by StereoRectificationGridGenerator) have to contain the transform between the original geometry (stereo pair) and the epipolar geometry (disparity map). The algorithm for each disparity is the following :  * skip if position is discarded by the disparity mask  * compute left ray : transform the current position from epipolar geometry to left sensor geometry (left rectification grid)  * compute right ray : shift the current position with current disparity and transform from epipolar geometry to right sensor (right rectification grid)  * estimate best 3D intersection between left and right rays  * for the ground cell of the obtained 3D point, keep its elevation if greater than current elevation (keeps the maximum of elevations of all 3D points in each cell)Minimum and maximum elevations settings are here to bound the reconstructed DEM.",
         "id": "OTB.DisparityMapToElevationMap",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.DisparityMapToElevationMap",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.DisparityMapToElevationMap.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Projects a disparity map into a regular elevation map.",
         "version": "1.0.0"
        },
        {
         "description": "Compute statistics (mean and standard deviation) of the features in a set of OGR Layers, and write them in an XML file. This XML file can then be used by the training application.",
         "id": "OTB.ComputeOGRLayersFeaturesStatistics",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.ComputeOGRLayersFeaturesStatistics",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.ComputeOGRLayersFeaturesStatistics.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Compute statistics of the features in a set of OGR Layers",
         "version": "1.0.0"
        },
        {
         "description": "This application performs the projection of an image into the geometry of another one.",
         "id": "OTB.Superimpose",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.Superimpose",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.Superimpose.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Using available image metadata, project one image onto another one",
         "version": "1.0.0"
        },
        {
         "description": "This application performs grayscale morphological operations on a mono band image",
         "id": "OTB.GrayScaleMorphologicalOperation",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.GrayScaleMorphologicalOperation",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.GrayScaleMorphologicalOperation.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Performs morphological operations on a grayscale input image",
         "version": "1.0.0"
        },
        {
         "description": "Unsupervised Self Organizing Map image classification.",
         "id": "OTB.SOMClassification",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.SOMClassification",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.SOMClassification.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "SOM image classification.",
         "version": "1.0.0"
        },
        {
         "description": "This application performs a classifier training from multiple pairs of input images and training vector data. Samples are composed of pixel values in each band optionally centered and reduced using an XML statistics file produced by the ComputeImagesStatistics application. The training vector data must contain polygons with a positive integer field representing the class label. The name of this field can be set using the \"Class label field\" parameter. Training and validation sample lists are built such that each class is equally represented in both lists. One parameter allows controlling the ratio between the number of samples in training and validation sets. Two parameters allow managing the size of the training and validation sets per class and per image. Several classifier parameters can be set depending on the chosen classifier. In the validation process, the confusion matrix is organized the following way: rows = reference labels, columns = produced labels. In the header of the optional confusion matrix output file, the validation (reference) and predicted (produced) class labels are ordered according to the rows/columns of the confusion matrix. This application is based on LibSVM, OpenCV Machine Learning (2.3.1 and later), and Shark ML. The output of this application is a text model file, whose format corresponds to the ML model type chosen. There is no image nor vector data output.",
         "id": "OTB.TrainImagesClassifier",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.TrainImagesClassifier",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.TrainImagesClassifier.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Train a classifier from multiple pairs of images and training vector data.",
         "version": "1.0.0"
        },
        {
         "description": "This application allows reprojecting and rasterize a vector dataset. The grid of the rasterized output can be set by using a reference image, or by setting all parmeters (origin, size, spacing) by hand. In the latter case, at least the spacing (ground sampling distance) is needed (other parameters are computed automatically). The rasterized output can also be in a different projection reference system than the input dataset. There are two rasterize mode available in the application. The first is the binary mode: it allows rendering all pixels belonging to a geometry of the input dataset in the foreground color, while rendering the other in background color. The second one allows rendering pixels belonging to a geometry woth respect to an attribute of this geometry. The field of the attribute to render can be set by the user. In the second mode, the background value is still used for unassociated pixels.",
         "id": "OTB.Rasterization",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.Rasterization",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.Rasterization.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Rasterize a vector dataset.",
         "version": "1.0.0"
        },
        {
         "description": "This application performs P+XS pansharpening. The default mode use Pan and XS sensor models to estimate the transformation to superimpose XS over Pan before the fusion (\"default mode\"). The application provides also a PHR mode for Pleiades images which does not use sensor models as Pan and XS products are already coregistered but only estimate an affine transformation to superimpose XS over the Pan.Note that this option is automatically activated in case Pleiades images are detected as input.",
         "id": "OTB.BundleToPerfectSensor",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.BundleToPerfectSensor",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.BundleToPerfectSensor.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Perform P+XS pansharpening",
         "version": "1.0.0"
        },
        {
         "description": "Generates a subsampled version of an extract of an image defined by ROIStart and ROISize. This extract is subsampled using the ratio OR the output image Size.",
         "id": "OTB.Quicklook",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.Quicklook",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.Quicklook.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Generates a subsampled version of an image extract",
         "version": "1.0.0"
        },
        {
         "description": "This application computes three sets of Haralick features [1][2].  * simple: a set of 8 local Haralick features: Energy (texture uniformity) , Entropy (measure of randomness of intensity image), Correlation (how correlated a pixel is to its neighborhood), Inverse Difference Moment (measures the texture homogeneity), Inertia (intensity contrast between a pixel and its neighborhood), Cluster Shade, Cluster Prominence, Haralick Correlation;  * advanced: a set of 10 advanced Haralick features : Mean, Variance (measures the texture heterogeneity), Dissimilarity, Sum Average, Sum Variance, Sum Entropy, Difference of Entropies, Difference of Variances, IC1, IC2;  * higher: a set of 11 higher Haralick features : Short Run Emphasis (measures the texture sharpness), Long Run Emphasis (measures the texture roughness), Grey-Level Nonuniformity, Run Length Nonuniformity, Run Percentage (measures the texture sharpness homogeneity), Low Grey-Level Run Emphasis, High Grey-Level Run Emphasis, Short Run Low Grey-Level Emphasis, Short Run High Grey-Level Emphasis, Long Run Low Grey-Level Emphasis and Long Run High Grey-Level Emphasis.",
         "id": "OTB.HaralickTextureExtraction",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.HaralickTextureExtraction",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.HaralickTextureExtraction.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Computes Haralick textural features on the selected channel of the input image",
         "version": "1.0.0"
        },
        {
         "description": "This application computes the 4 local statistical moments on every pixel in the selected channel of the input image, over a specified neighborhood. The output image is multi band with one statistical moment (feature) per band. Thus, the 4 output features are the Mean, the Variance, the Skewness and the Kurtosis. They are provided in this exact order in the output image.",
         "id": "OTB.LocalStatisticExtraction",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.LocalStatisticExtraction",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.LocalStatisticExtraction.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Computes local statistical moments on every pixel in the selected channel of the input image",
         "version": "1.0.0"
        },
        {
         "description": "This application computes a disparity map between two images that correspond to the same scene. It is intended for case where small misregistration between images should be estimated and fixed. The search is performed in 2D.The algorithm uses an iterative approach to estimate a best match between local patches. The typical use case is registration betwween similar bands, or between two acquisitions. The output image contains X and Y offsets, as well as the metric value. A sub-pixel accuracy can be expected. The input images should have the same size and same physical space.",
         "id": "OTB.FineRegistration",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.FineRegistration",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.FineRegistration.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Estimate disparity map between two images.",
         "version": "1.0.0"
        },
        {
         "description": "This application chains together the 4 steps of the MeanShit framework, that is the MeanShiftSmoothing [1], the LSMSSegmentation [2], the LSMSSmallRegionsMerging [3] and the LSMSVectorization [4].This application can be a preliminary step for an object-based analysis.It generates a vector data file containing the regions extracted with the MeanShift algorithm. The spatial and range radius parameters allow adapting the sensitivity of the algorithm depending on the image dynamic and resolution. There is a step to remove small regions whose size (in pixels) is less than the given 'minsize' parameter. These regions are merged to a similar neighbor region. In the output vectors, there are additional fields to describe each region. In particular the mean and standard deviation (for each band) is computed for each region using the input image as support. If an optional 'imfield' image is given, it will be used as support image instead.",
         "id": "OTB.LargeScaleMeanShift",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.LargeScaleMeanShift",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.LargeScaleMeanShift.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Large-scale segmentation using MeanShift",
         "version": "1.0.0"
        },
        {
         "description": "This application computes the geographic coordinates from cartographic ones. User has to give the X and Y coordinate and the cartographic projection (see mapproj parameter for details).",
         "id": "OTB.ConvertCartoToGeoPoint",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.ConvertCartoToGeoPoint",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.ConvertCartoToGeoPoint.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Convert cartographic coordinates to geographic ones.",
         "version": "1.0.0"
        },
        {
         "description": "The application applies a linear unmixing algorithmto an hyperspectral data cube. This method supposes that the mixture betweenaterials in the scene is macroscopic and simulates a linear mixing model ofspectra.The Linear Mixing Model (LMM) acknowledges that reflectancespectrum associated with each pixel is a linear combination of purematerials in the recovery area, commonly known as endmembers. Endmembers canbe estimated using the VertexComponentAnalysis application.The application allows estimating the abundance maps with several algorithms :  * Unconstrained Least Square (ucls)  * Image Space Reconstruction Algorithm (isra)  * Non-negative constrained  * Least Square (ncls)  * Minimum Dispersion Constrained Non Negative Matrix Factorization (MDMDNMF).",
         "id": "OTB.HyperspectralUnmixing",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.HyperspectralUnmixing",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.HyperspectralUnmixing.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Estimate abundance maps from an hyperspectral image and a set of endmembers.",
         "version": "1.0.0"
        },
        {
         "description": "This application performs a mathematical operation on several multi-band images and outputs the result into a monoband image. The given expression is computed at each pixel position. Evaluation of the mathematical formula is done by the muParser libraries.The formula can be written using:  * numerical values ( 2.3, -5, 3.1e4, ...)  * variables containing pixel values (e.g. : 'im2b3' is the pixel value in 2nd image, 3rd band)  * binary operators:    * '+' addition, '-' subtraction, '*' multiplication, '/' division    * '^' raise x to the power of y    * '",
         "id": "OTB.BandMath",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.BandMath",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.BandMath.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Outputs a monoband image which is the result of a mathematical operation on several multi-band images.",
         "version": "1.0.0"
        },
        {
         "description": "This application computes a global mean and standard deviation for each band of a set of images and optionally saves the results in an XML file. The output XML is intended to be used as an input for the TrainImagesClassifier application to normalize samples before learning. You can also normalize the image with the XML file in the ImageClassifier application.",
         "id": "OTB.ComputeImagesStatistics",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.ComputeImagesStatistics",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.ComputeImagesStatistics.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Computes global mean and standard deviation for each band from a set of images and optionally saves the results in an XML file.",
         "version": "1.0.0"
        },
        {
         "description": "This application concatenates a list of vector data files to produce a unique vector data output file.This application will gather all the geometries from the input files and write them into an output vector data file. Any format supported by OGR can be used. Ideally, all inputs should have the same set of fields and the same spatial reference system.",
         "id": "OTB.ConcatenateVectorData",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.ConcatenateVectorData",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.ConcatenateVectorData.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Concatenate vector data files",
         "version": "1.0.0"
        },
        {
         "description": "The objective of SAR calibration is to provide imagery in which the pixel values can be directly related to the radar backscatter of the scene. This application allows computing Sigma Naught (Radiometric Calibration) for TerraSAR-X, Sentinel1 L1 and Radarsat-2 sensors. Metadata are automatically retrieved from image products.The application supports complex and non-complex images (SLC or detected products).",
         "id": "OTB.SARCalibration",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.SARCalibration",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.SARCalibration.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Perform radiometric calibration of SAR images. Following sensors are supported: TerraSAR-X, Sentinel1 and Radarsat-2.Both Single Look Complex(SLC) and detected products are supported as input.",
         "version": "1.0.0"
        },
        {
         "description": "This application applies a smoothing filter to an image. Three methodes can be used : a gaussian filter , a mean filter , or an anisotropic diffusion using the Perona-Malik algorithm.",
         "id": "OTB.Smoothing",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.Smoothing",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.Smoothing.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Apply a smoothing filter to an image",
         "version": "1.0.0"
        },
        {
         "description": "Compute the ground elevation with a stereo block matching algorithm between one or multiple stereo pair in sensor geometry. The output is projected in desired geographic or cartographic map projection (WGS84 by default).This application is chaining different processing steps. Some of them are also performed by other applications in the stereo-reconstruction framework:  * StereoRectificationGridGenerator [1] : for the generation of deformation grids  * GridBasedImageResampling [2] : resampling into epipolar geometry  * BlockMatching [3] : estimation of dense disparity mapsThe pipeline executes the following steps on each stereo pair:  - compute the epipolar displacement grids from the stereo pair (direct and inverse)  - resample the stereo pair into epipolar geometry using BCO interpolation  - create masks for each epipolar image : remove black borders and resample input masks  - compute horizontal disparities with a block matching algorithm  - refine disparities to sub-pixel precision with a dichotomy algorithm  - apply an optional median filter  - filter disparities based on the correlation score and exploration bounds  - translate disparities in sensor geometry  - convert disparity to 3D Map.Then all 3D maps are fused to produce DSM. The fusion method in each DEM cell can be chosen between maximum, minimum and average.",
         "id": "OTB.StereoFramework",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.StereoFramework",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.StereoFramework.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Compute the ground elevation based on one or multiple stereo pair(s)",
         "version": "1.0.0"
        },
        {
         "description": "The application processes a set of geometries intended for training (they should have a field giving the associated class). The geometries are analyzed against a support image to compute statistics :   - number of samples per class  - number of samples per geometryAn optional raster mask can be used to discard samples. Different types of geometry are supported : polygons, lines, points. The behaviour is different for each type of geometry :  - polygon: select pixels whose center is inside the polygon  - lines  : select pixels intersecting the line  - points : select closest pixel to the point",
         "id": "OTB.PolygonClassStatistics",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.PolygonClassStatistics",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.PolygonClassStatistics.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Computes statistics on a training polygon set.",
         "version": "1.0.0"
        },
        {
         "description": "This application extracts the vector data features belonging to a region specified by the support image envelope. Any features intersecting the support region is copied to output. The output geometries are NOT cropped.",
         "id": "OTB.VectorDataExtractROI",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.VectorDataExtractROI",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.VectorDataExtractROI.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Perform an extract ROI on the input vector data according to the input image extent",
         "version": "1.0.0"
        },
        {
         "description": "Build a vector data containing the image envelope polygon. Useful for some projection, you can set the polygon with more points with the sr parameter. This filter supports user-specified output projection. If no projection is defined, the standard WGS84 projection will be used.",
         "id": "OTB.ImageEnvelope",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.ImageEnvelope",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.ImageEnvelope.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Extracts an image envelope.",
         "version": "1.0.0"
        },
        {
         "description": "This application has two modes. The first allows building a mask of no-data pixels from the no-data flags read from the image file. The second allows updating the change the no-data value of an image (pixels value and metadata). This last mode also allows replacing NaN in images with a proper no-data value. To do so, one should activate the NaN is no-data option.",
         "id": "OTB.ManageNoData",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.ManageNoData",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.ManageNoData.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Manage No-Data",
         "version": "1.0.0"
        },
        {
         "description": "MeanShift [1,2,3] is an iterative edge-preserving image smoothing algorithm often used in image processing and as a first step for image segmentation. The MeanShift algorithm can be applied to multispectral images.At first iteration, for any given pixel of the input image, the filtered value correspond to the average spectral signature of neighborhood pixels that are both spatially closer than the spatial radius parameter (spatialr) and with spectral signature that have an euclidean distance to the input pixel lower than the range radius (ranger), that is, pixels that are both close in space and in spectral signatures. Subsequent iterations will repeat this process by considering that the pixel signature corresponds to the average spectral signature computed during previous iteration, and that the pixel position corresponds to the average position of pixels used to compute the average signature.The algorithm stops when the maximum number of iterations (maxiter) is reached, or when the position and spectral signature does not change much between iterations, according to the convergence threshold (thres). If the modesearch option is used then convergence will also stops if the spatial position reaches a pixel that has already converged. This will speed-up convergence, at the expense of stability of the result.The application outputs the image of the final averaged spectral signatures (fout), and can also optionally output the 2D displacement field between input pixel position and final pixel position after convergence (foutpos).Note that computing an euclidean distance between spectral signatures may be inaccurate and that techniques such as color space transform or image normalisation could be applied before using this application. Also note that most satellite images noise model is not gaussian, since noise variance linearly depends on radiance (the higher the radiance, the higher the noise variance). To account for such noise model, the application provides the range radius ramp option (rangeramp), which will vary the range radius linearly with the central pixel intensity. Default value is 1. (no ramp).This application is the first step of the large scale MeanShift method depicted in [4]. Both outputs (fout and foutpos) can be passed to the large scale MeanShift segmentation application [5]. If the application is used for large scale MeanShift, modesearch option should be off.",
         "id": "OTB.MeanShiftSmoothing",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.MeanShiftSmoothing",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.MeanShiftSmoothing.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "This application smooths an image using the MeanShift algorithm.",
         "version": "1.0.0"
        },
        {
         "description": "This application allows reprojecting a vector data using support image projection reference, or a user given map projection. If given, image keywordlist can be added to reprojected vectordata.",
         "id": "OTB.VectorDataReprojection",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.VectorDataReprojection",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.VectorDataReprojection.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Reproject a vector data using support image projection reference, or a user specified map projection",
         "version": "1.0.0"
        },
        {
         "description": "This application computes the confusion matrix of a classification map relative to a ground truth dataset. This ground truth can be given as a raster or a vector data. Only reference and produced pixels with values different from NoData are handled in the calculation of the confusion matrix. The confusion matrix is organized the following way: rows = reference labels, columns = produced labels. In the header of the output file, the reference and produced class labels are ordered according to the rows/columns of the confusion matrix.",
         "id": "OTB.ComputeConfusionMatrix",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.ComputeConfusionMatrix",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.ComputeConfusionMatrix.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Computes the confusion matrix of a classification",
         "version": "1.0.0"
        },
        {
         "description": "Display information about the input image like: image size, origin, spacing, metadata, projections...",
         "id": "OTB.ReadImageInfo",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.ReadImageInfo",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.ReadImageInfo.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Get information about the image",
         "version": "1.0.0"
        },
        {
         "description": "This application performs a parametric transform on the input image. Scaling, translation and rotation with scaling factor are handled. Parameters of the transform is expressed in physical units, thus particular attention must be paid on pixel size (value, and sign). Moreover transform is expressed from input space to output space (on the contrary ITK Transforms are expressed form output space to input space). ",
         "id": "OTB.RigidTransformResample",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.RigidTransformResample",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.RigidTransformResample.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Resample an image with a rigid transform",
         "version": "1.0.0"
        },
        {
         "description": "This application performs change detection between two multispectral images using the Multivariate Alteration Detector (MAD) [1] algorithm.The MAD algorithm produces a set of N change maps (where N is the maximum number of bands in first and second input images), with the following properties: - Change maps are differences of a pair of linear combinations of  bands from image 1 and bands from image 2 chosen to maximize the  correlation,  - Each change map is orthogonal to the others. This is a statistical method which can handle different modalities and even different bands and number of bands between images.  The application will output all change maps into a single multiband image. If numbers of bands in image 1 and 2 are equal, then change maps are sorted by increasing correlation. If number of bands is different, the change maps are sorted by decreasing correlation.  The application will also print the following information:- Mean1 and Mean2 which are the mean values of bands for both input images,- V1 and V2 which are the two linear transform that are applied to input image 1 and input image 2 to build the change map,- Rho, the vector of correlation associated to each change map. The OTB filter used in this application has been implemented from the Matlab code kindly made available by the authors here [2]. Both cases (same and different number of bands) have been validated by comparing the output image to the output produced by the Matlab  code, and the reference images for testing have been generated from  the Matlab code using Octave.",
         "id": "OTB.MultivariateAlterationDetector",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/OTB.MultivariateAlterationDetector",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/OTB.MultivariateAlterationDetector.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Change detection by Multivariate Alteration Detector (MAD) algorithm",
         "version": "1.0.0"
        },
        {
         "description": "Computes the edges of Voronoi diagram for a set of data points.",
         "id": "RVoronoi",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/RVoronoi",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/RVoronoi.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Voronoi Diagram. ",
         "version": "2.0.0"
        },
        {
         "description": "Output and Hello Wolrd string",
         "id": "failR",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/failR",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/failR.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "HelloWorld Service in R",
         "version": "2.0.0"
        },
        {
         "description": "Output and Hello Wolrd string",
         "id": "hellojs1",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/hellojs1",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/hellojs1.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "HelloWorld Service in JavaScript",
         "version": "2.0.0"
        },
        {
         "description": "Print Cheetah templates as HTML.",
         "id": "display",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/display",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/display.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Print Cheetah templates as HTML",
         "version": "2.0.0"
        },
        {
         "description": "Output and Hello Wolrd string",
         "id": "hellojs",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/hellojs",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/hellojs.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "HelloWorld Service in JavaScript",
         "version": "2.0.0"
        },
        {
         "description": "Output and Hello Wolrd string",
         "id": "hellor",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/hellor",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/hellor.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "HelloWorld Service in R",
         "version": "2.0.0"
        },
        {
         "description": "Create a welcome string.",
         "id": "HelloPy",
         "jobControlOptions": [
          "sync-execute",
          "async-execute",
          "dismiss"
         ],
         "links": [
          {
           "href": "http://localhost/ogc-api/processes/HelloPy",
           "rel": "self",
           "title": "Process Description",
           "type": "application/json"
          },
          {
           "href": "http://localhost/ogc-api/processes/HelloPy.html",
           "rel": "alternate",
           "title": "Process Description",
           "type": "text/html"
          }
         ],
         "outputTransmission": [
          "value",
          "reference"
         ],
         "title": "Create a welcome message string.",
         "version": "2.0.0"
        }
       ]
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML, JSON\n",
    "import requests\n",
    "\n",
    "oapip_endpoint = 'http://localhost:8000/cgi-bin/zoo_loader.cgi?'\n",
    "\n",
    "headers= {\"accept\": \"application/json\"}\n",
    "\n",
    "query = '{}/processes'.format(oapip_endpoint)\n",
    "\n",
    "r = requests.get(query, headers=headers)\n",
    "\n",
    "JSON(r.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### TrainImagesClassifier\n",
    "\n",
    "Using `/processes/{processId}` path, you can fecth the detailled description of a service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "description": "This application performs a mathematical operation on several multi-band images and outputs the result into an image (multi- or mono-band, as opposed to the BandMath OTB-application). The mathematical formula is done by the muParserX libraries.The list of features and the syntax of muParserX is available at [1].As opposed to muParser (and thus the BandMath OTB-application [2]), muParserX supports vector expressions which allows outputting multi-band images.Hereafter is a brief reference of the muParserX syntaxFundamentals------------The formula can be written using:  * numerical values ( 2.3, -5, 3.1e4, ...)  * variables containing pixel values (please, note the indexing of inputs from 1 to N). Examples for the first input image:    * 'im1' a pixel from 1st input, made of n components (n bands)    * 'im1b2' the 2nd component of a pixel from 1st input (band index is 1-based)    * 'im1b2N3x4' a 3x4 pixels 'N'eighbourhood of a pixel the 2nd component of a pixel from the 1st input    * 'im1PhyX' horizontal (X-axis) spacing of the 1st input.    * 'im1PhyY' vertical spacing of the 1st input input.    * 'im1b2Mean' mean of the 2nd component of the 1st input (global statistics)    * 'im1b2Mini' minimum of the 2nd component of the 1st input (global statistics)    * 'im1b2Maxi' maximum of the 2nd component of the 1st input (global statistics)    * 'im1b2Sum' sum of the 2nd component of the 1st input (global statistics)    * 'im1b2Var' variance of the 2nd component of the 1st input (global statistics)    * 'idxX' and 'idxY' are the indices of the current pixel (generic variables)  * binary operators:    * '+' addition, '-' subtraction, '*' multiplication, '/' division    * '^' raise x to the power of y    * '",
       "id": "OTB.BandMathX",
       "inputs": {
        "exp": {
         "description": "Mathematical expression to apply.",
         "schema": {
          "default": "Any value",
          "type": "string"
         },
         "title": "Mathematical expression to apply."
        },
        "il": {
         "description": "Image-list to perform computation on.",
         "extended-schema": {
          "items": {
           "oneOf": [
            {
             "allOf": [
              {
               "$ref": "http://zoo-project.org/dl/link.json"
              },
              {
               "properties": {
                "type": {
                 "enum": [
                  "image/tiff",
                  "image/jpeg",
                  "image/png"
                 ]
                }
               },
               "type": "object"
              }
             ]
            },
            {
             "properties": {
              "value": {
               "oneOf": [
                {
                 "contentEncoding": "base64",
                 "contentMediaType": "image/tiff",
                 "type": "string"
                },
                {
                 "contentEncoding": "base64",
                 "contentMediaType": "image/jpeg",
                 "type": "string"
                },
                {
                 "contentEncoding": "base64",
                 "contentMediaType": "image/png",
                 "type": "string"
                }
               ]
              }
             },
             "required": [
              "value"
             ],
             "type": "object"
            }
           ]
          },
          "maxItems": 1024,
          "minItems": 1,
          "type": "array"
         },
         "maxOccurs": 1024,
         "schema": {
          "oneOf": [
           {
            "contentEncoding": "base64",
            "contentMediaType": "image/tiff",
            "type": "string"
           },
           {
            "contentEncoding": "base64",
            "contentMediaType": "image/jpeg",
            "type": "string"
           },
           {
            "contentEncoding": "base64",
            "contentMediaType": "image/png",
            "type": "string"
           }
          ]
         },
         "title": "Image-list to perform computation on."
        },
        "incontext": {
         "description": "A txt file containing user's constants and expressions.",
         "extended-schema": {
          "nullable": true,
          "oneOf": [
           {
            "allOf": [
             {
              "$ref": "http://zoo-project.org/dl/link.json"
             },
             {
              "properties": {
               "type": {
                "enum": [
                 "image/tiff",
                 "image/jpeg",
                 "image/png"
                ]
               }
              },
              "type": "object"
             }
            ]
           },
           {
            "properties": {
             "value": {
              "oneOf": [
               {
                "contentEncoding": "base64",
                "contentMediaType": "image/tiff",
                "type": "string"
               },
               {
                "contentEncoding": "base64",
                "contentMediaType": "image/jpeg",
                "type": "string"
               },
               {
                "contentEncoding": "base64",
                "contentMediaType": "image/png",
                "type": "string"
               }
              ]
             }
            },
            "required": [
             "value"
            ],
            "type": "object"
           }
          ]
         },
         "schema": {
          "oneOf": [
           {
            "contentEncoding": "base64",
            "contentMediaType": "image/tiff",
            "type": "string"
           },
           {
            "contentEncoding": "base64",
            "contentMediaType": "image/jpeg",
            "type": "string"
           },
           {
            "contentEncoding": "base64",
            "contentMediaType": "image/png",
            "type": "string"
           }
          ]
         },
         "title": "A txt file containing user's constants and expressions."
        },
        "out": {
         "description": "Output image.",
         "schema": {
          "default": "float",
          "enum": [
           "uint8",
           "uint16",
           "int16",
           "int32",
           "int32",
           "float",
           "double"
          ],
          "type": "string"
         },
         "title": "Output image."
        },
        "ram": {
         "description": "Available memory for processing (in MB)",
         "schema": {
          "default": 128,
          "nullable": true,
          "type": "integer"
         },
         "title": "Available memory for processing (in MB)"
        }
       },
       "jobControlOptions": [
        "sync-execute",
        "async-execute",
        "dismiss"
       ],
       "links": [
        {
         "href": "http://localhost/ogc-api/processes/OTB.BandMathX/execution",
         "rel": "http://www.opengis.net/def/rel/ogc/1.0/execute",
         "title": "Execute End Point",
         "type": "application/json"
        },
        {
         "href": "http://localhost/ogc-api/processes/OTB.BandMathX/execution.html",
         "rel": "alternate",
         "title": "Execute End Point",
         "type": "text/html"
        }
       ],
       "outputTransmission": [
        "value",
        "reference"
       ],
       "outputs": {
        "out": {
         "description": "Output image.",
         "extended-schema": {
          "oneOf": [
           {
            "allOf": [
             {
              "$ref": "http://zoo-project.org/dl/link.json"
             },
             {
              "properties": {
               "type": {
                "enum": [
                 "image/tiff",
                 "image/jpeg",
                 "image/png"
                ]
               }
              },
              "type": "object"
             }
            ]
           },
           {
            "properties": {
             "value": {
              "oneOf": [
               {
                "contentEncoding": "base64",
                "contentMediaType": "image/tiff",
                "type": "string"
               },
               {
                "contentEncoding": "base64",
                "contentMediaType": "image/jpeg",
                "type": "string"
               },
               {
                "contentEncoding": "base64",
                "contentMediaType": "image/png",
                "type": "string"
               }
              ]
             }
            },
            "required": [
             "value"
            ],
            "type": "object"
           }
          ]
         },
         "schema": {
          "oneOf": [
           {
            "contentEncoding": "base64",
            "contentMediaType": "image/tiff",
            "type": "string"
           },
           {
            "contentEncoding": "base64",
            "contentMediaType": "image/jpeg",
            "type": "string"
           },
           {
            "contentEncoding": "base64",
            "contentMediaType": "image/png",
            "type": "string"
           }
          ]
         },
         "title": "Output image."
        },
        "outcontext": {
         "description": "A txt file where to save user's constants and expressions.",
         "extended-schema": {
          "oneOf": [
           {
            "allOf": [
             {
              "$ref": "http://zoo-project.org/dl/link.json"
             },
             {
              "properties": {
               "type": {
                "enum": [
                 "text/xml",
                 "text/plain"
                ]
               }
              },
              "type": "object"
             }
            ]
           },
           {
            "properties": {
             "value": {
              "oneOf": [
               {
                "contentEncoding": "utf-8",
                "contentMediaType": "text/xml",
                "type": "string"
               },
               {
                "contentEncoding": "utf-8",
                "contentMediaType": "text/plain",
                "type": "string"
               }
              ]
             }
            },
            "required": [
             "value"
            ],
            "type": "object"
           }
          ]
         },
         "schema": {
          "oneOf": [
           {
            "contentEncoding": "utf-8",
            "contentMediaType": "text/xml",
            "type": "string"
           },
           {
            "contentEncoding": "utf-8",
            "contentMediaType": "text/plain",
            "type": "string"
           }
          ]
         },
         "title": "A txt file where to save user's constants and expressions."
        }
       },
       "title": "This application performs mathematical operations on several multiband images.",
       "version": "1.0.0"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required modules\n",
    "from IPython.core.display import HTML, JSON\n",
    "import requests\n",
    "# Define Endpoint\n",
    "oapip_endpoint = 'http://localhost:8000/cgi-bin/zoo_loader.cgi?'\n",
    "# Define headers to use\n",
    "headers= {\"accept\": \"application/json\"}\n",
    "# Define the query path\n",
    "query = '{}/processes/OTB.BandMathX'.format(oapip_endpoint)\n",
    "# Run the query\n",
    "r = requests.get(query, headers=headers)\n",
    "# Output JSON\n",
    "JSON(r.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MapServer\n",
    "\n",
    "As before, we will run from the command line or using the Python snipest bellow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<HTML>\n",
       "<HEAD><TITLE>MapServer Message</TITLE></HEAD>\n",
       "<!-- MapServer version 7.7-dev OUTPUT=PNG OUTPUT=JPEG OUTPUT=KML SUPPORTS=PROJ SUPPORTS=AGG SUPPORTS=FREETYPE SUPPORTS=CAIRO SUPPORTS=ICONV SUPPORTS=FRIBIDI SUPPORTS=WMS_SERVER SUPPORTS=WMS_CLIENT SUPPORTS=WFS_SERVER SUPPORTS=WFS_CLIENT SUPPORTS=WCS_SERVER SUPPORTS=OGCAPI_SERVER SUPPORTS=FASTCGI SUPPORTS=GEOS SUPPORTS=PBF INPUT=JPEG INPUT=POSTGIS INPUT=OGR INPUT=GDAL INPUT=SHAPEFILE -->\n",
       "<BODY BGCOLOR=\"#FFFFFF\">\n",
       "msCGILoadMap(): Web application error. CGI variable &quot;map&quot; fails to validate.\n",
       "</BODY></HTML>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!curl \"http://localhost:8000/cgi-bin/mapserv?\"\n",
    "\n",
    "from IPython.core.display import HTML, JSON\n",
    "import requests\n",
    "\n",
    "ms_endpoint = 'http://localhost:8000/cgi-bin/mapserv?map=/tmp/demo.map'\n",
    "\n",
    "query = '{}/'.format(ms_endpoint)\n",
    "\n",
    "r = requests.get(query)\n",
    "\n",
    "HTML(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
      "<wps:ExecuteResponse xmlns:ows=\"http://www.opengis.net/ows/1.1\" xmlns:wps=\"http://www.opengis.net/wps/1.0.0\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.opengis.net/wps/1.0.0 http://schemas.opengis.net/wps/1.0.0/wpsExecute_response.xsd\" service=\"WPS\" version=\"1.0.0\" xml:lang=\"en-US\" serviceInstance=\"http://bb858467c741/cgi-bin/zoo_loader.cgi\">\n",
      "  <wps:Process wps:processVersion=\"2\">\n",
      "    <ows:Identifier>HelloPy</ows:Identifier>\n",
      "    <ows:Title>Create a welcome message string.</ows:Title>\n",
      "    <ows:Abstract>Create a welcome string.</ows:Abstract>\n",
      "  </wps:Process>\n",
      "  <wps:Status creationTime=\"2022-05-25T02:54:04Z\">\n",
      "    <wps:ProcessSucceeded>The service \"HelloPy\" ran successfully.</wps:ProcessSucceeded>\n",
      "  </wps:Status>\n",
      "  <wps:ProcessOutputs>\n",
      "    <wps:Output>\n",
      "      <ows:Identifier>Result</ows:Identifier>\n",
      "      <ows:Title>The welcome message</ows:Title>\n",
      "      <ows:Abstract>The welcome message created by service.</ows:Abstract>\n",
      "      <wps:Data>\n",
      "        <wps:LiteralData DataType=\"string\" UOM=\"meter\">Hello Martin et Jules from Python World !</wps:LiteralData>\n",
      "      </wps:Data>\n",
      "    </wps:Output>\n",
      "  </wps:ProcessOutputs>\n",
      "</wps:ExecuteResponse>\n"
     ]
    }
   ],
   "source": [
    "!curl \"http://localhost:8000/cgi-bin/zoo_loader.cgi?service=WPS&version=1.0.0&request=Execute&Identifier=HelloPy&DataInputs=a=Martin%20et%20Jules;toto=Reference@href=https://gitlab.orfeo-toolbox.org/cs-si/otb-data/-/raw/release-5.6/Examples/verySmallFSATSW.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Martin et Jules from Python World !"
     ]
    }
   ],
   "source": [
    "!curl \"http://localhost:8000/cgi-bin/zoo_loader.cgi?service=WPS&version=1.0.0&request=Execute&Identifier=HelloPy&DataInputs=a=Martin%20et%20Jules&RawDataOutput=Result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
      "<ows:ExceptionReport xmlns:ows=\"http://www.opengis.net/ows/1.1\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.opengis.net/ows/1.1 http://schemas.opengis.net/ows/1.1.0/owsExceptionReport.xsd\" xml:lang=\"en-US\" version=\"1.1.0\">\n",
      "  <ows:Exception exceptionCode=\"InternalError\">\n",
      "    <ows:ExceptionText>Unable to run the Service. The message returned back by the Service was the following: Unable to load your R file</ows:ExceptionText>\n",
      "  </ows:Exception>\n",
      "</ows:ExceptionReport>\n"
     ]
    }
   ],
   "source": [
    "!curl \"http://localhost:8000/cgi-bin/zoo_loader.cgi?service=WPS&version=1.0.0&request=Execute&Identifier=hellor&DataInputs=S=Martin%20et%20Jules&RawDataOutput=Result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -v -d @/home/jovyan/work/workspace/assets/requests/test.txt -H \"Content-Type: application/json\" \"http://localhost:8000/cgi-bin/zoo_loader.cgi?/processes/HelloPy/execution\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content-Type: application/json;charset=UTF-8\n",
      "Content-Length: 42\n",
      "Content-Type: text/plain; charset=utf-8\n",
      "Status: 200 OK\n",
      "\n",
      "Hello Martin and Jules from Python World !"
     ]
    }
   ],
   "source": [
    "!REQUEST_METHOD=POST CONTENT_TYPE=application/json zoo_loader.cgi /processes/HelloPy/execution < /WholeTale/workspace/assets/requests/test.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"jobs\":[],\"links\":[{\"rel\":\"self\",\"type\":\"application\\/json\",\"href\":\"http:\\/\\/localhost\\/ogc-api\\/jobs\"},{\"rel\":\"alternate\",\"type\":\"text\\/html\",\"href\":\"http:\\/\\/localhost\\/ogc-api\\/jobs.html\"}],\"numberTotal\":0}\n"
     ]
    }
   ],
   "source": [
    "!curl http://localhost:8000/cgi-bin/zoo_loader.cgi?/jobs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<{}{}<Status: 500 Not Implemented\n",
      "\n",
      "{\"title\":\"NoApplicableCode\",\"detail\":\"ZOO Kernel failed to process your request, receiving signal 11 = SIGSEGV \"}"
     ]
    }
   ],
   "source": [
    "!REQUEST_METHOD=POST CONTENT_TYPE=application/json zoo_loader.cgi /processes/OTB.BandMathX/execution < /WholeTale/workspace/assets/requests/test2.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content-Type: application/json;charset=UTF-8\n",
      "Status: 200 OK \n",
      "\n",
      "{\"id\":\"OTB.BandMathX\",\"title\":\"This application performs mathematical operations on several multiband images.\",\"description\":\"This application performs a mathematical operation on several multi-band images and outputs the result into an image (multi- or mono-band, as opposed to the BandMath OTB-application). The mathematical formula is done by the muParserX libraries.The list of features and the syntax of muParserX is available at [1].As opposed to muParser (and thus the BandMath OTB-application [2]), muParserX supports vector expressions which allows outputting multi-band images.Hereafter is a brief reference of the muParserX syntaxFundamentals------------The formula can be written using:  * numerical values ( 2.3, -5, 3.1e4, ...)  * variables containing pixel values (please, note the indexing of inputs from 1 to N). Examples for the first input image:    * 'im1' a pixel from 1st input, made of n components (n bands)    * 'im1b2' the 2nd component of a pixel from 1st input (band index is 1-based)    * 'im1b2N3x4' a 3x4 pixels 'N'eighbourhood of a pixel the 2nd component of a pixel from the 1st input    * 'im1PhyX' horizontal (X-axis) spacing of the 1st input.    * 'im1PhyY' vertical spacing of the 1st input input.    * 'im1b2Mean' mean of the 2nd component of the 1st input (global statistics)    * 'im1b2Mini' minimum of the 2nd component of the 1st input (global statistics)    * 'im1b2Maxi' maximum of the 2nd component of the 1st input (global statistics)    * 'im1b2Sum' sum of the 2nd component of the 1st input (global statistics)    * 'im1b2Var' variance of the 2nd component of the 1st input (global statistics)    * 'idxX' and 'idxY' are the indices of the current pixel (generic variables)  * binary operators:    * '+' addition, '-' subtraction, '*' multiplication, '\\/' division    * '^' raise x to the power of y    * '\",\"version\":\"1.0.0\",\"jobControlOptions\":[\"sync-execute\",\"async-execute\",\"dismiss\"],\"outputTransmission\":[\"value\",\"reference\"],\"links\":[{\"rel\":\"http:\\/\\/www.opengis.net\\/def\\/rel\\/ogc\\/1.0\\/execute\",\"type\":\"application\\/json\",\"title\":\"Execute End Point\",\"href\":\"http:\\/\\/localhost\\/ogc-api\\/processes\\/OTB.BandMathX\\/execution\"},{\"rel\":\"alternate\",\"type\":\"text\\/html\",\"title\":\"Execute End Point\",\"href\":\"http:\\/\\/localhost\\/ogc-api\\/processes\\/OTB.BandMathX\\/execution.html\"}],\"inputs\":{\"il\":{\"title\":\"Image-list to perform computation on.\",\"description\":\"Image-list to perform computation on.\",\"maxOccurs\":1024,\"extended-schema\":{\"type\":\"array\",\"minItems\":1,\"maxItems\":1024,\"items\":{\"oneOf\":[{\"allOf\":[{\"$ref\":\"http:\\/\\/zoo-project.org\\/dl\\/link.json\"},{\"type\":\"object\",\"properties\":{\"type\":{\"enum\":[\"image\\/tiff\",\"image\\/jpeg\",\"image\\/png\"]}}}]},{\"type\":\"object\",\"required\":[\"value\"],\"properties\":{\"value\":{\"oneOf\":[{\"type\":\"string\",\"contentEncoding\":\"base64\",\"contentMediaType\":\"image\\/tiff\"},{\"type\":\"string\",\"contentEncoding\":\"base64\",\"contentMediaType\":\"image\\/jpeg\"},{\"type\":\"string\",\"contentEncoding\":\"base64\",\"contentMediaType\":\"image\\/png\"}]}}}]}},\"schema\":{\"oneOf\":[{\"type\":\"string\",\"contentEncoding\":\"base64\",\"contentMediaType\":\"image\\/tiff\"},{\"type\":\"string\",\"contentEncoding\":\"base64\",\"contentMediaType\":\"image\\/jpeg\"},{\"type\":\"string\",\"contentEncoding\":\"base64\",\"contentMediaType\":\"image\\/png\"}]}},\"out\":{\"title\":\"Output image.\",\"description\":\"Output image.\",\"schema\":{\"type\":\"string\",\"default\":\"float\",\"enum\":[\"uint8\",\"uint16\",\"int16\",\"int32\",\"int32\",\"float\",\"double\"]}},\"ram\":{\"title\":\"Available memory for processing (in MB)\",\"description\":\"Available memory for processing (in MB)\",\"schema\":{\"type\":\"integer\",\"default\":128,\"nullable\":true}},\"exp\":{\"title\":\"Mathematical expression to apply.\",\"description\":\"Mathematical expression to apply.\",\"schema\":{\"type\":\"string\",\"default\":\"Any value\"}},\"incontext\":{\"title\":\"A txt file containing user's constants and expressions.\",\"description\":\"A txt file containing user's constants and expressions.\",\"extended-schema\":{\"oneOf\":[{\"allOf\":[{\"$ref\":\"http:\\/\\/zoo-project.org\\/dl\\/link.json\"},{\"type\":\"object\",\"properties\":{\"type\":{\"enum\":[\"image\\/tiff\",\"image\\/jpeg\",\"image\\/png\"]}}}]},{\"type\":\"object\",\"required\":[\"value\"],\"properties\":{\"value\":{\"oneOf\":[{\"type\":\"string\",\"contentEncoding\":\"base64\",\"contentMediaType\":\"image\\/tiff\"},{\"type\":\"string\",\"contentEncoding\":\"base64\",\"contentMediaType\":\"image\\/jpeg\"},{\"type\":\"string\",\"contentEncoding\":\"base64\",\"contentMediaType\":\"image\\/png\"}]}}}],\"nullable\":true},\"schema\":{\"oneOf\":[{\"type\":\"string\",\"contentEncoding\":\"base64\",\"contentMediaType\":\"image\\/tiff\"},{\"type\":\"string\",\"contentEncoding\":\"base64\",\"contentMediaType\":\"image\\/jpeg\"},{\"type\":\"string\",\"contentEncoding\":\"base64\",\"contentMediaType\":\"image\\/png\"}]}}},\"outputs\":{\"out\":{\"title\":\"Output image.\",\"description\":\"Output image.\",\"extended-schema\":{\"oneOf\":[{\"allOf\":[{\"$ref\":\"http:\\/\\/zoo-project.org\\/dl\\/link.json\"},{\"type\":\"object\",\"properties\":{\"type\":{\"enum\":[\"image\\/tiff\",\"image\\/jpeg\",\"image\\/png\"]}}}]},{\"type\":\"object\",\"required\":[\"value\"],\"properties\":{\"value\":{\"oneOf\":[{\"type\":\"string\",\"contentEncoding\":\"base64\",\"contentMediaType\":\"image\\/tiff\"},{\"type\":\"string\",\"contentEncoding\":\"base64\",\"contentMediaType\":\"image\\/jpeg\"},{\"type\":\"string\",\"contentEncoding\":\"base64\",\"contentMediaType\":\"image\\/png\"}]}}}]},\"schema\":{\"oneOf\":[{\"type\":\"string\",\"contentEncoding\":\"base64\",\"contentMediaType\":\"image\\/tiff\"},{\"type\":\"string\",\"contentEncoding\":\"base64\",\"contentMediaType\":\"image\\/jpeg\"},{\"type\":\"string\",\"contentEncoding\":\"base64\",\"contentMediaType\":\"image\\/png\"}]}},\"outcontext\":{\"title\":\"A txt file where to save user's constants and expressions.\",\"description\":\"A txt file where to save user's constants and expressions.\",\"extended-schema\":{\"oneOf\":[{\"allOf\":[{\"$ref\":\"http:\\/\\/zoo-project.org\\/dl\\/link.json\"},{\"type\":\"object\",\"properties\":{\"type\":{\"enum\":[\"text\\/xml\",\"text\\/plain\"]}}}]},{\"type\":\"object\",\"required\":[\"value\"],\"properties\":{\"value\":{\"oneOf\":[{\"type\":\"string\",\"contentEncoding\":\"utf-8\",\"contentMediaType\":\"text\\/xml\"},{\"type\":\"string\",\"contentEncoding\":\"utf-8\",\"contentMediaType\":\"text\\/plain\"}]}}}]},\"schema\":{\"oneOf\":[{\"type\":\"string\",\"contentEncoding\":\"utf-8\",\"contentMediaType\":\"text\\/xml\"},{\"type\":\"string\",\"contentEncoding\":\"utf-8\",\"contentMediaType\":\"text\\/plain\"}]}}}}\n"
     ]
    }
   ],
   "source": [
    "!zoo_loader.cgi /processes/OTB.BandMathX 2> log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop the web server\n",
    "\n",
    "Here are the commands to follow to stop the http server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill -9 $(ps axvfwww | grep http | awk '{print $1}' | head -1) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
